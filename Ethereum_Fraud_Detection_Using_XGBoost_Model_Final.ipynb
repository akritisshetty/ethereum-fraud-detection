{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fraud Detection in Ethereum Dataset using XGBoost Model"
      ],
      "metadata": {
        "id": "WbTEplauTWPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR GENERATING REAL TIME DATASET\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples\n",
        "n_samples = 10000\n",
        "fraud_ratio = 0.55  # 22% fraud (similar to original dataset)\n",
        "n_fraud = int(n_samples * fraud_ratio)\n",
        "n_clean = n_samples - n_fraud\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ETHEREUM FRAUD DETECTION - DUMMY DATASET GENERATOR\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Generating {n_samples:,} transactions...\")\n",
        "print(f\"   Clean: {n_clean:,} ({(n_clean/n_samples)*100:.1f}%)\")\n",
        "print(f\"   Fraud: {n_fraud:,} ({(n_fraud/n_samples)*100:.1f}%)\")\n",
        "\n",
        "# Generate Ethereum addresses (dummy format)\n",
        "def generate_eth_address(n):\n",
        "    addresses = []\n",
        "    for i in range(n):\n",
        "        address = '0x' + ''.join(np.random.choice(list('0123456789abcdef'), 40))\n",
        "        addresses.append(address)\n",
        "    return addresses\n",
        "\n",
        "# Create base features for CLEAN transactions\n",
        "clean_data = {\n",
        "    'Unnamed: 0': np.arange(n_clean),\n",
        "    'Index': np.arange(1, n_clean + 1),\n",
        "    'Address': generate_eth_address(n_clean),\n",
        "    'FLAG': np.zeros(n_clean, dtype=int),\n",
        "\n",
        "    # Transaction timing patterns (clean transactions are more regular)\n",
        "    'Avg min between sent tnx': np.random.exponential(5000, n_clean),\n",
        "    'Avg min between received tnx': np.random.exponential(8000, n_clean),\n",
        "    'Time Diff between first and last (Mins)': np.random.uniform(10000, 1500000, n_clean),\n",
        "\n",
        "    # Transaction counts (clean = moderate activity)\n",
        "    'Sent tnx': np.random.poisson(50, n_clean),\n",
        "    'Received Tnx': np.random.poisson(80, n_clean),\n",
        "    'Number of Created Contracts': np.random.poisson(1, n_clean),\n",
        "    'Unique Received From Addresses': np.random.poisson(15, n_clean),\n",
        "    'Unique Sent To Addresses': np.random.poisson(8, n_clean),\n",
        "\n",
        "    # Transaction values (clean = normal distribution)\n",
        "    'min value received': np.random.exponential(0.1, n_clean),\n",
        "    'max value received': np.random.exponential(50, n_clean) + 10,\n",
        "    'avg val received': np.random.exponential(5, n_clean) + 1,\n",
        "    'min val sent': np.random.exponential(0.1, n_clean),\n",
        "    'max val sent': np.random.exponential(40, n_clean) + 5,\n",
        "    'avg val sent': np.random.exponential(4, n_clean) + 0.5,\n",
        "\n",
        "    # Contract values\n",
        "    'min value sent to contract': np.random.exponential(0.05, n_clean),\n",
        "    'max val sent to contract': np.random.exponential(20, n_clean),\n",
        "    'avg value sent to contract': np.random.exponential(2, n_clean),\n",
        "\n",
        "    # Total transaction metrics\n",
        "    'total transactions (including tnx to create contract': np.random.poisson(130, n_clean),\n",
        "    'total Ether sent': np.random.exponential(200, n_clean) + 10,\n",
        "    'total ether received': np.random.exponential(300, n_clean) + 20,\n",
        "    'total ether sent contracts': np.random.exponential(50, n_clean),\n",
        "    'total ether balance': np.random.uniform(-50, 500, n_clean),\n",
        "}\n",
        "\n",
        "# ERC20 Token features (with some missing values)\n",
        "erc20_mask = np.random.random(n_clean) > 0.08  # 92% have ERC20 data\n",
        "\n",
        "clean_data[' Total ERC20 tnxs'] = np.where(erc20_mask, np.random.poisson(10, n_clean), np.nan)\n",
        "clean_data[' ERC20 total Ether received'] = np.where(erc20_mask, np.random.exponential(100000, n_clean), np.nan)\n",
        "clean_data[' ERC20 total ether sent'] = np.where(erc20_mask, np.random.exponential(80000, n_clean), np.nan)\n",
        "clean_data[' ERC20 total Ether sent contract'] = np.where(erc20_mask, np.random.exponential(10000, n_clean), np.nan)\n",
        "clean_data[' ERC20 uniq sent addr'] = np.where(erc20_mask, np.random.poisson(3, n_clean), np.nan)\n",
        "clean_data[' ERC20 uniq rec addr'] = np.where(erc20_mask, np.random.poisson(8, n_clean), np.nan)\n",
        "clean_data[' ERC20 uniq sent addr.1'] = np.where(erc20_mask, np.random.poisson(3, n_clean), np.nan)\n",
        "clean_data[' ERC20 uniq rec contract addr'] = np.where(erc20_mask, np.random.poisson(2, n_clean), np.nan)\n",
        "\n",
        "clean_data[' ERC20 avg time between sent tnx'] = np.where(erc20_mask, np.random.exponential(15000, n_clean), np.nan)\n",
        "clean_data[' ERC20 avg time between rec tnx'] = np.where(erc20_mask, np.random.exponential(12000, n_clean), np.nan)\n",
        "clean_data[' ERC20 avg time between rec 2 tnx'] = np.where(erc20_mask, np.random.exponential(11000, n_clean), np.nan)\n",
        "clean_data[' ERC20 avg time between contract tnx'] = np.where(erc20_mask, np.random.exponential(20000, n_clean), np.nan)\n",
        "\n",
        "clean_data[' ERC20 min val rec'] = np.where(erc20_mask, np.random.exponential(1000, n_clean), np.nan)\n",
        "clean_data[' ERC20 max val rec'] = np.where(erc20_mask, np.random.exponential(500000, n_clean), np.nan)\n",
        "clean_data[' ERC20 avg val rec'] = np.where(erc20_mask, np.random.exponential(50000, n_clean), np.nan)\n",
        "clean_data[' ERC20 min val sent'] = np.where(erc20_mask, np.random.exponential(800, n_clean), np.nan)\n",
        "clean_data[' ERC20 max val sent'] = np.where(erc20_mask, np.random.exponential(400000, n_clean), np.nan)\n",
        "clean_data[' ERC20 avg val sent'] = np.where(erc20_mask, np.random.exponential(40000, n_clean), np.nan)\n",
        "\n",
        "clean_data[' ERC20 min val sent contract'] = np.zeros(n_clean)\n",
        "clean_data[' ERC20 max val sent contract'] = np.zeros(n_clean)\n",
        "clean_data[' ERC20 avg val sent contract'] = np.zeros(n_clean)\n",
        "\n",
        "clean_data[' ERC20 uniq sent token name'] = np.where(erc20_mask, np.random.poisson(2, n_clean), np.nan)\n",
        "clean_data[' ERC20 uniq rec token name'] = np.where(erc20_mask, np.random.poisson(6, n_clean), np.nan)\n",
        "\n",
        "# Token types (categorical)\n",
        "token_types = ['USDT', 'USDC', 'DAI', 'LINK', 'UNI', 'AAVE', 'WETH', 'MATIC', None]\n",
        "clean_data[' ERC20 most sent token type'] = np.random.choice(token_types, n_clean, p=[0.15, 0.12, 0.10, 0.08, 0.08, 0.07, 0.10, 0.05, 0.25])\n",
        "clean_data[' ERC20_most_rec_token_type'] = np.random.choice(token_types, n_clean, p=[0.18, 0.14, 0.12, 0.09, 0.09, 0.08, 0.12, 0.06, 0.12])\n",
        "\n",
        "# Create base features for FRAUD transactions\n",
        "fraud_data = {\n",
        "    'Unnamed: 0': np.arange(n_clean, n_samples),\n",
        "    'Index': np.arange(n_clean + 1, n_samples + 1),\n",
        "    'Address': generate_eth_address(n_fraud),\n",
        "    'FLAG': np.ones(n_fraud, dtype=int),\n",
        "\n",
        "    # Fraud transactions have different patterns:\n",
        "    # 1. Very short time between transactions (automated bots)\n",
        "    'Avg min between sent tnx': np.random.exponential(100, n_fraud),  # Much shorter\n",
        "    'Avg min between received tnx': np.random.exponential(500, n_fraud),  # Much shorter\n",
        "    'Time Diff between first and last (Mins)': np.random.uniform(100, 500000, n_fraud),  # Shorter lifespan\n",
        "\n",
        "    # 2. High transaction volume (money laundering patterns)\n",
        "    'Sent tnx': np.random.poisson(200, n_fraud),  # More transactions\n",
        "    'Received Tnx': np.random.poisson(250, n_fraud),  # More transactions\n",
        "    'Number of Created Contracts': np.random.poisson(10, n_fraud),  # More contracts\n",
        "    'Unique Received From Addresses': np.random.poisson(50, n_fraud),  # More sources\n",
        "    'Unique Sent To Addresses': np.random.poisson(60, n_fraud),  # More destinations\n",
        "\n",
        "    # 3. Unusual value patterns (round numbers, very small/large amounts)\n",
        "    'min value received': np.random.exponential(0.001, n_fraud),  # Very small\n",
        "    'max value received': np.random.exponential(200, n_fraud) + 100,  # Higher\n",
        "    'avg val received': np.random.exponential(15, n_fraud) + 5,  # Higher average\n",
        "    'min val sent': np.random.exponential(0.001, n_fraud),  # Very small\n",
        "    'max val sent': np.random.exponential(150, n_fraud) + 80,  # Higher\n",
        "    'avg val sent': np.random.exponential(12, n_fraud) + 3,  # Higher average\n",
        "\n",
        "    # Contract interaction (fraud often involves contracts)\n",
        "    'min value sent to contract': np.random.exponential(0.01, n_fraud),\n",
        "    'max val sent to contract': np.random.exponential(100, n_fraud) + 20,\n",
        "    'avg value sent to contract': np.random.exponential(10, n_fraud) + 2,\n",
        "\n",
        "    # Total metrics (higher volume for fraud)\n",
        "    'total transactions (including tnx to create contract': np.random.poisson(450, n_fraud),\n",
        "    'total Ether sent': np.random.exponential(1000, n_fraud) + 100,\n",
        "    'total ether received': np.random.exponential(1200, n_fraud) + 150,\n",
        "    'total ether sent contracts': np.random.exponential(300, n_fraud) + 50,\n",
        "    'total ether balance': np.random.uniform(-200, 200, n_fraud),  # Often low/negative\n",
        "}\n",
        "\n",
        "# ERC20 for fraud (fraud accounts more likely to have ERC20 activity)\n",
        "erc20_mask_fraud = np.random.random(n_fraud) > 0.05  # 95% have ERC20 data\n",
        "\n",
        "fraud_data[' Total ERC20 tnxs'] = np.where(erc20_mask_fraud, np.random.poisson(50, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 total Ether received'] = np.where(erc20_mask_fraud, np.random.exponential(1000000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 total ether sent'] = np.where(erc20_mask_fraud, np.random.exponential(900000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 total Ether sent contract'] = np.where(erc20_mask_fraud, np.random.exponential(200000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 uniq sent addr'] = np.where(erc20_mask_fraud, np.random.poisson(15, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 uniq rec addr'] = np.where(erc20_mask_fraud, np.random.poisson(25, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 uniq sent addr.1'] = np.where(erc20_mask_fraud, np.random.poisson(15, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 uniq rec contract addr'] = np.where(erc20_mask_fraud, np.random.poisson(8, n_fraud), np.nan)\n",
        "\n",
        "fraud_data[' ERC20 avg time between sent tnx'] = np.where(erc20_mask_fraud, np.random.exponential(1000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 avg time between rec tnx'] = np.where(erc20_mask_fraud, np.random.exponential(800, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 avg time between rec 2 tnx'] = np.where(erc20_mask_fraud, np.random.exponential(750, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 avg time between contract tnx'] = np.where(erc20_mask_fraud, np.random.exponential(2000, n_fraud), np.nan)\n",
        "\n",
        "fraud_data[' ERC20 min val rec'] = np.where(erc20_mask_fraud, np.random.exponential(5000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 max val rec'] = np.where(erc20_mask_fraud, np.random.exponential(5000000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 avg val rec'] = np.where(erc20_mask_fraud, np.random.exponential(500000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 min val sent'] = np.where(erc20_mask_fraud, np.random.exponential(4000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 max val sent'] = np.where(erc20_mask_fraud, np.random.exponential(4000000, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 avg val sent'] = np.where(erc20_mask_fraud, np.random.exponential(400000, n_fraud), np.nan)\n",
        "\n",
        "fraud_data[' ERC20 min val sent contract'] = np.zeros(n_fraud)\n",
        "fraud_data[' ERC20 max val sent contract'] = np.zeros(n_fraud)\n",
        "fraud_data[' ERC20 avg val sent contract'] = np.zeros(n_fraud)\n",
        "\n",
        "fraud_data[' ERC20 uniq sent token name'] = np.where(erc20_mask_fraud, np.random.poisson(8, n_fraud), np.nan)\n",
        "fraud_data[' ERC20 uniq rec token name'] = np.where(erc20_mask_fraud, np.random.poisson(20, n_fraud), np.nan)\n",
        "\n",
        "# Fraud uses more obscure tokens\n",
        "fraud_token_types = ['SHIB', 'PEPE', 'FLOKI', 'DOGE', 'USDT', 'SCAM', 'FAKE', 'PONZI', None]\n",
        "fraud_data[' ERC20 most sent token type'] = np.random.choice(fraud_token_types, n_fraud, p=[0.15, 0.12, 0.10, 0.12, 0.10, 0.08, 0.08, 0.10, 0.15])\n",
        "fraud_data[' ERC20_most_rec_token_type'] = np.random.choice(fraud_token_types, n_fraud, p=[0.18, 0.14, 0.12, 0.13, 0.12, 0.09, 0.09, 0.08, 0.05])\n",
        "\n",
        "# Create DataFrames\n",
        "df_clean = pd.DataFrame(clean_data)\n",
        "df_fraud = pd.DataFrame(fraud_data)\n",
        "\n",
        "# Combine and shuffle\n",
        "df = pd.concat([df_clean, df_fraud], ignore_index=True)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Update Unnamed: 0 and Index after shuffling\n",
        "df['Unnamed: 0'] = np.arange(len(df))\n",
        "df['Index'] = np.arange(1, len(df) + 1)\n",
        "\n",
        "# Save to CSV\n",
        "filename = 'mydata.csv'\n",
        "df.to_csv(filename, index=False)\n",
        "\n",
        "print(f\"\\n✓ Dataset generated successfully!\")\n",
        "print(f\"✓ Saved to: {filename}\")\n",
        "print(f\"✓ File size: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
        "\n",
        "# Also create a backup with timestamp for safety\n",
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "backup_filename = f'transaction_dataset_backup_{timestamp}.csv'\n",
        "df.to_csv(backup_filename, index=False)\n",
        "print(f\"✓ Backup saved to: {backup_filename}\")\n",
        "\n",
        "# Display statistics\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATASET STATISTICS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total transactions: {len(df):,}\")\n",
        "print(f\"Features: {df.shape[1]}\")\n",
        "print(f\"\\nClass Distribution:\")\n",
        "print(df['FLAG'].value_counts())\n",
        "print(f\"\\nFraud: {df['FLAG'].sum():,} ({df['FLAG'].mean()*100:.2f}%)\")\n",
        "print(f\"Clean: {(df['FLAG']==0).sum():,} ({(1-df['FLAG'].mean())*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nMissing Values:\")\n",
        "missing_summary = df.isnull().sum()\n",
        "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
        "if len(missing_summary) > 0:\n",
        "    print(f\"Columns with missing values: {len(missing_summary)}\")\n",
        "    print(missing_summary.head(10))\n",
        "else:\n",
        "    print(\"No missing values\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SAMPLE DATA\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KEY FEATURE COMPARISONS (Clean vs Fraud)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "comparison_features = [\n",
        "    'Avg min between sent tnx',\n",
        "    'Sent tnx',\n",
        "    'Received Tnx',\n",
        "    'total Ether sent',\n",
        "    ' Total ERC20 tnxs'\n",
        "]\n",
        "\n",
        "for feature in comparison_features:\n",
        "    if feature in df.columns:\n",
        "        clean_mean = df[df['FLAG'] == 0][feature].mean()\n",
        "        fraud_mean = df[df['FLAG'] == 1][feature].mean()\n",
        "        print(f\"\\n{feature}:\")\n",
        "        print(f\"   Clean: {clean_mean:.2f}\")\n",
        "        print(f\"   Fraud: {fraud_mean:.2f}\")\n",
        "        print(f\"   Ratio: {fraud_mean/clean_mean:.2f}x\")"
      ],
      "metadata": {
        "id": "GLpODpjnTU_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eacf481-0103-4f65-e221-f271306bf65e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ETHEREUM FRAUD DETECTION - DUMMY DATASET GENERATOR\n",
            "================================================================================\n",
            "Generating 10,000 transactions...\n",
            "   Clean: 4,500 (45.0%)\n",
            "   Fraud: 5,500 (55.0%)\n",
            "\n",
            "✓ Dataset generated successfully!\n",
            "✓ Saved to: mydata.csv\n",
            "✓ File size: 5593.16 KB\n",
            "✓ Backup saved to: transaction_dataset_backup_20251109_153947.csv\n",
            "\n",
            "================================================================================\n",
            "DATASET STATISTICS\n",
            "================================================================================\n",
            "Total transactions: 10,000\n",
            "Features: 51\n",
            "\n",
            "Class Distribution:\n",
            "FLAG\n",
            "1    5500\n",
            "0    4500\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Fraud: 5,500 (55.00%)\n",
            "Clean: 4,500 (45.00%)\n",
            "\n",
            "Missing Values:\n",
            "Columns with missing values: 22\n",
            "ERC20 most sent token type         2072\n",
            "ERC20_most_rec_token_type           811\n",
            "ERC20 total ether sent              601\n",
            "ERC20 total Ether sent contract     601\n",
            "Total ERC20 tnxs                    601\n",
            "ERC20 total Ether received          601\n",
            "ERC20 uniq rec addr                 601\n",
            "ERC20 uniq sent addr                601\n",
            "ERC20 uniq sent addr.1              601\n",
            "ERC20 uniq rec contract addr        601\n",
            "dtype: int64\n",
            "\n",
            "================================================================================\n",
            "SAMPLE DATA\n",
            "================================================================================\n",
            "\n",
            "First 5 rows:\n",
            "   Unnamed: 0  Index                                     Address  FLAG  \\\n",
            "0           0      1  0xcea1bee6387add3cf4f5ec054c028185bbd5d4fe     1   \n",
            "1           1      2  0xeb71ffd67842707dd7763011edba9b55b8ef217d     1   \n",
            "2           2      3  0x72506a6c1439c8bc12c0942bf3e35966edea724b     0   \n",
            "3           3      4  0x28baa73bbf681b62dc668a6842ff8ff24fcd6813     1   \n",
            "4           4      5  0x724a9401f50813da25374f34a84d204707c6adc2     1   \n",
            "\n",
            "   Avg min between sent tnx  Avg min between received tnx  \\\n",
            "0                 21.543460                   1778.274159   \n",
            "1                 29.539527                     28.838359   \n",
            "2               8992.066377                  11413.995351   \n",
            "3                160.342143                    538.619814   \n",
            "4                 23.044445                    121.652563   \n",
            "\n",
            "   Time Diff between first and last (Mins)  Sent tnx  Received Tnx  \\\n",
            "0                            106193.687448       200           264   \n",
            "1                            105590.597403       215           247   \n",
            "2                            563347.896832        56            83   \n",
            "3                            417367.160480       184           240   \n",
            "4                             67418.468100       179           249   \n",
            "\n",
            "   Number of Created Contracts  ...   ERC20 min val sent   ERC20 max val sent  \\\n",
            "0                           10  ...           312.707724         6.831099e+05   \n",
            "1                            9  ...          2516.779233         1.233734e+07   \n",
            "2                            0  ...           233.691547         5.527171e+05   \n",
            "3                           11  ...          2164.009555         4.856242e+06   \n",
            "4                            9  ...         22015.611257         3.677521e+06   \n",
            "\n",
            "    ERC20 avg val sent   ERC20 min val sent contract  \\\n",
            "0         1.170159e+06                           0.0   \n",
            "1         3.012109e+05                           0.0   \n",
            "2         1.340407e+04                           0.0   \n",
            "3         1.316660e+05                           0.0   \n",
            "4         2.649423e+05                           0.0   \n",
            "\n",
            "    ERC20 max val sent contract   ERC20 avg val sent contract  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "3                           0.0                           0.0   \n",
            "4                           0.0                           0.0   \n",
            "\n",
            "    ERC20 uniq sent token name   ERC20 uniq rec token name  \\\n",
            "0                         14.0                        26.0   \n",
            "1                          3.0                        21.0   \n",
            "2                          3.0                         7.0   \n",
            "3                          9.0                        16.0   \n",
            "4                         11.0                        14.0   \n",
            "\n",
            "    ERC20 most sent token type   ERC20_most_rec_token_type  \n",
            "0                        FLOKI                        PEPE  \n",
            "1                         SHIB                        FAKE  \n",
            "2                         USDT                        AAVE  \n",
            "3                         SHIB                        PEPE  \n",
            "4                        FLOKI                       PONZI  \n",
            "\n",
            "[5 rows x 51 columns]\n",
            "\n",
            "================================================================================\n",
            "KEY FEATURE COMPARISONS (Clean vs Fraud)\n",
            "================================================================================\n",
            "\n",
            "Avg min between sent tnx:\n",
            "   Clean: 4904.76\n",
            "   Fraud: 98.17\n",
            "   Ratio: 0.02x\n",
            "\n",
            "Sent tnx:\n",
            "   Clean: 50.03\n",
            "   Fraud: 200.00\n",
            "   Ratio: 4.00x\n",
            "\n",
            "Received Tnx:\n",
            "   Clean: 79.89\n",
            "   Fraud: 249.93\n",
            "   Ratio: 3.13x\n",
            "\n",
            "total Ether sent:\n",
            "   Clean: 208.86\n",
            "   Fraud: 1091.14\n",
            "   Ratio: 5.22x\n",
            "\n",
            " Total ERC20 tnxs:\n",
            "   Clean: 10.10\n",
            "   Fraud: 50.01\n",
            "   Ratio: 4.95x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, accuracy_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix,\n",
        "    classification_report, precision_recall_curve, auc\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "dMEo2w9eBfd6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"ETHEREUM FRAUD DETECTION - XGBOOST\")\n",
        "\n",
        "df = pd.read_csv(\"transaction_dataset.csv\")\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Rows: {df.shape[0]:,} | Columns: {df.shape[1]}\")\n",
        "\n",
        "print(\"\\nEXPLORATORY DATA ANALYSIS\")\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nFirst Few Rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing,\n",
        "    'Percentage': missing_pct\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "fraud_col = 'FLAG'\n",
        "if fraud_col in df.columns:\n",
        "    print(f\"\\nClass Distribution ({fraud_col}):\")\n",
        "    class_dist = df[fraud_col].value_counts()\n",
        "    print(class_dist)\n",
        "    fraud_pct = (class_dist.get(1, 0) / len(df)) * 100\n",
        "    clean_pct = (class_dist.get(0, 0) / len(df)) * 100\n",
        "    print(f\"Fraud Percentage: {fraud_pct:.2f}%\")\n",
        "    print(f\"Clean Percentage: {clean_pct:.2f}%\")\n",
        "\n",
        "    imbalance_ratio = class_dist.get(0, 0) / max(class_dist.get(1, 1), 1)\n",
        "    print(f\"Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
        "    y = df[fraud_col]\n",
        "else:\n",
        "    print(\"Warning: Could not find fraud label column!\")\n",
        "    y = pd.Series([0] * len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR3fgN0JBfyO",
        "outputId": "89d81392-8a6f-4d3a-bd52-d43eb3e2a828"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETHEREUM FRAUD DETECTION - XGBOOST\n",
            "Dataset Shape: (9841, 51)\n",
            "Rows: 9,841 | Columns: 51\n",
            "\n",
            "EXPLORATORY DATA ANALYSIS\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9841 entries, 0 to 9840\n",
            "Data columns (total 51 columns):\n",
            " #   Column                                                Non-Null Count  Dtype  \n",
            "---  ------                                                --------------  -----  \n",
            " 0   Unnamed: 0                                            9841 non-null   int64  \n",
            " 1   Index                                                 9841 non-null   int64  \n",
            " 2   Address                                               9841 non-null   object \n",
            " 3   FLAG                                                  9841 non-null   int64  \n",
            " 4   Avg min between sent tnx                              9841 non-null   float64\n",
            " 5   Avg min between received tnx                          9841 non-null   float64\n",
            " 6   Time Diff between first and last (Mins)               9841 non-null   float64\n",
            " 7   Sent tnx                                              9841 non-null   int64  \n",
            " 8   Received Tnx                                          9841 non-null   int64  \n",
            " 9   Number of Created Contracts                           9841 non-null   int64  \n",
            " 10  Unique Received From Addresses                        9841 non-null   int64  \n",
            " 11  Unique Sent To Addresses                              9841 non-null   int64  \n",
            " 12  min value received                                    9841 non-null   float64\n",
            " 13  max value received                                    9841 non-null   float64\n",
            " 14  avg val received                                      9841 non-null   float64\n",
            " 15  min val sent                                          9841 non-null   float64\n",
            " 16  max val sent                                          9841 non-null   float64\n",
            " 17  avg val sent                                          9841 non-null   float64\n",
            " 18  min value sent to contract                            9841 non-null   float64\n",
            " 19  max val sent to contract                              9841 non-null   float64\n",
            " 20  avg value sent to contract                            9841 non-null   float64\n",
            " 21  total transactions (including tnx to create contract  9841 non-null   int64  \n",
            " 22  total Ether sent                                      9841 non-null   float64\n",
            " 23  total ether received                                  9841 non-null   float64\n",
            " 24  total ether sent contracts                            9841 non-null   float64\n",
            " 25  total ether balance                                   9841 non-null   float64\n",
            " 26   Total ERC20 tnxs                                     9012 non-null   float64\n",
            " 27   ERC20 total Ether received                           9012 non-null   float64\n",
            " 28   ERC20 total ether sent                               9012 non-null   float64\n",
            " 29   ERC20 total Ether sent contract                      9012 non-null   float64\n",
            " 30   ERC20 uniq sent addr                                 9012 non-null   float64\n",
            " 31   ERC20 uniq rec addr                                  9012 non-null   float64\n",
            " 32   ERC20 uniq sent addr.1                               9012 non-null   float64\n",
            " 33   ERC20 uniq rec contract addr                         9012 non-null   float64\n",
            " 34   ERC20 avg time between sent tnx                      9012 non-null   float64\n",
            " 35   ERC20 avg time between rec tnx                       9012 non-null   float64\n",
            " 36   ERC20 avg time between rec 2 tnx                     9012 non-null   float64\n",
            " 37   ERC20 avg time between contract tnx                  9012 non-null   float64\n",
            " 38   ERC20 min val rec                                    9012 non-null   float64\n",
            " 39   ERC20 max val rec                                    9012 non-null   float64\n",
            " 40   ERC20 avg val rec                                    9012 non-null   float64\n",
            " 41   ERC20 min val sent                                   9012 non-null   float64\n",
            " 42   ERC20 max val sent                                   9012 non-null   float64\n",
            " 43   ERC20 avg val sent                                   9012 non-null   float64\n",
            " 44   ERC20 min val sent contract                          9012 non-null   float64\n",
            " 45   ERC20 max val sent contract                          9012 non-null   float64\n",
            " 46   ERC20 avg val sent contract                          9012 non-null   float64\n",
            " 47   ERC20 uniq sent token name                           9012 non-null   float64\n",
            " 48   ERC20 uniq rec token name                            9012 non-null   float64\n",
            " 49   ERC20 most sent token type                           7144 non-null   object \n",
            " 50   ERC20_most_rec_token_type                            8970 non-null   object \n",
            "dtypes: float64(39), int64(9), object(3)\n",
            "memory usage: 3.8+ MB\n",
            "None\n",
            "\n",
            "First Few Rows:\n",
            "   Unnamed: 0  Index                                     Address  FLAG  \\\n",
            "0           0      1  0x00009277775ac7d0d59eaad8fee3d10ac6c805e8     0   \n",
            "1           1      2  0x0002b44ddb1476db43c868bd494422ee4c136fed     0   \n",
            "2           2      3  0x0002bda54cb772d040f779e88eb453cac0daa244     0   \n",
            "3           3      4  0x00038e6ba2fd5c09aedb96697c8d7b8fa6632e5e     0   \n",
            "4           4      5  0x00062d1dd1afb6fb02540ddad9cdebfe568e0d89     0   \n",
            "\n",
            "   Avg min between sent tnx  Avg min between received tnx  \\\n",
            "0                    844.26                       1093.71   \n",
            "1                  12709.07                       2958.44   \n",
            "2                 246194.54                       2434.02   \n",
            "3                  10219.60                      15785.09   \n",
            "4                     36.61                      10707.77   \n",
            "\n",
            "   Time Diff between first and last (Mins)  Sent tnx  Received Tnx  \\\n",
            "0                                704785.63       721            89   \n",
            "1                               1218216.73        94             8   \n",
            "2                                516729.30         2            10   \n",
            "3                                397555.90        25             9   \n",
            "4                                382472.42      4598            20   \n",
            "\n",
            "   Number of Created Contracts  ...   ERC20 min val sent   ERC20 max val sent  \\\n",
            "0                            0  ...             0.000000         1.683100e+07   \n",
            "1                            0  ...             2.260809         2.260809e+00   \n",
            "2                            0  ...             0.000000         0.000000e+00   \n",
            "3                            0  ...           100.000000         9.029231e+03   \n",
            "4                            1  ...             0.000000         4.500000e+04   \n",
            "\n",
            "    ERC20 avg val sent   ERC20 min val sent contract  \\\n",
            "0        271779.920000                           0.0   \n",
            "1             2.260809                           0.0   \n",
            "2             0.000000                           0.0   \n",
            "3          3804.076893                           0.0   \n",
            "4         13726.659220                           0.0   \n",
            "\n",
            "    ERC20 max val sent contract   ERC20 avg val sent contract  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "3                           0.0                           0.0   \n",
            "4                           0.0                           0.0   \n",
            "\n",
            "    ERC20 uniq sent token name   ERC20 uniq rec token name  \\\n",
            "0                         39.0                        57.0   \n",
            "1                          1.0                         7.0   \n",
            "2                          0.0                         8.0   \n",
            "3                          1.0                        11.0   \n",
            "4                          6.0                        27.0   \n",
            "\n",
            "    ERC20 most sent token type   ERC20_most_rec_token_type  \n",
            "0                    Cofoundit                   Numeraire  \n",
            "1               Livepeer Token              Livepeer Token  \n",
            "2                          NaN                       XENON  \n",
            "3                       Raiden                       XENON  \n",
            "4                StatusNetwork                         EOS  \n",
            "\n",
            "[5 rows x 51 columns]\n",
            "\n",
            "Statistical Summary:\n",
            "        Unnamed: 0        Index         FLAG  Avg min between sent tnx  \\\n",
            "count  9841.000000  9841.000000  9841.000000               9841.000000   \n",
            "mean   4920.000000  1815.049893     0.221421               5086.878721   \n",
            "std    2840.996333  1222.621830     0.415224              21486.549974   \n",
            "min       0.000000     1.000000     0.000000                  0.000000   \n",
            "25%    2460.000000   821.000000     0.000000                  0.000000   \n",
            "50%    4920.000000  1641.000000     0.000000                 17.340000   \n",
            "75%    7380.000000  2601.000000     0.000000                565.470000   \n",
            "max    9840.000000  4729.000000     1.000000             430287.670000   \n",
            "\n",
            "       Avg min between received tnx  Time Diff between first and last (Mins)  \\\n",
            "count                   9841.000000                             9.841000e+03   \n",
            "mean                    8004.851184                             2.183333e+05   \n",
            "std                    23081.714801                             3.229379e+05   \n",
            "min                        0.000000                             0.000000e+00   \n",
            "25%                        0.000000                             3.169300e+02   \n",
            "50%                      509.770000                             4.663703e+04   \n",
            "75%                     5480.390000                             3.040710e+05   \n",
            "max                   482175.490000                             1.954861e+06   \n",
            "\n",
            "           Sent tnx  Received Tnx  Number of Created Contracts  \\\n",
            "count   9841.000000   9841.000000                  9841.000000   \n",
            "mean     115.931714    163.700945                     3.729702   \n",
            "std      757.226361    940.836550                   141.445583   \n",
            "min        0.000000      0.000000                     0.000000   \n",
            "25%        1.000000      1.000000                     0.000000   \n",
            "50%        3.000000      4.000000                     0.000000   \n",
            "75%       11.000000     27.000000                     0.000000   \n",
            "max    10000.000000  10000.000000                  9995.000000   \n",
            "\n",
            "       Unique Received From Addresses  ...   ERC20 max val rec  \\\n",
            "count                     9841.000000  ...        9.012000e+03   \n",
            "mean                        30.360939  ...        1.252524e+08   \n",
            "std                        298.621112  ...        1.053741e+10   \n",
            "min                          0.000000  ...        0.000000e+00   \n",
            "25%                          1.000000  ...        0.000000e+00   \n",
            "50%                          2.000000  ...        0.000000e+00   \n",
            "75%                          5.000000  ...        9.900000e+01   \n",
            "max                       9999.000000  ...        1.000000e+12   \n",
            "\n",
            "        ERC20 avg val rec   ERC20 min val sent   ERC20 max val sent  \\\n",
            "count        9.012000e+03         9.012000e+03         9.012000e+03   \n",
            "mean         4.346203e+06         1.174126e+04         1.303594e+07   \n",
            "std          2.141192e+08         1.053567e+06         1.179905e+09   \n",
            "min          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "25%          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "50%          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "75%          2.946467e+01         0.000000e+00         0.000000e+00   \n",
            "max          1.724181e+10         1.000000e+08         1.120000e+11   \n",
            "\n",
            "        ERC20 avg val sent   ERC20 min val sent contract  \\\n",
            "count         9.012000e+03                        9012.0   \n",
            "mean          6.318389e+06                           0.0   \n",
            "std           5.914764e+08                           0.0   \n",
            "min           0.000000e+00                           0.0   \n",
            "25%           0.000000e+00                           0.0   \n",
            "50%           0.000000e+00                           0.0   \n",
            "75%           0.000000e+00                           0.0   \n",
            "max           5.614756e+10                           0.0   \n",
            "\n",
            "        ERC20 max val sent contract   ERC20 avg val sent contract  \\\n",
            "count                        9012.0                        9012.0   \n",
            "mean                            0.0                           0.0   \n",
            "std                             0.0                           0.0   \n",
            "min                             0.0                           0.0   \n",
            "25%                             0.0                           0.0   \n",
            "50%                             0.0                           0.0   \n",
            "75%                             0.0                           0.0   \n",
            "max                             0.0                           0.0   \n",
            "\n",
            "        ERC20 uniq sent token name   ERC20 uniq rec token name  \n",
            "count                  9012.000000                 9012.000000  \n",
            "mean                      1.384931                    4.826676  \n",
            "std                       6.735121                   16.678607  \n",
            "min                       0.000000                    0.000000  \n",
            "25%                       0.000000                    0.000000  \n",
            "50%                       0.000000                    1.000000  \n",
            "75%                       0.000000                    2.000000  \n",
            "max                     213.000000                  737.000000  \n",
            "\n",
            "[8 rows x 48 columns]\n",
            "\n",
            "Missing Values:\n",
            "                                     Missing Count  Percentage\n",
            "Total ERC20 tnxs                               829    8.423941\n",
            "ERC20 total Ether received                     829    8.423941\n",
            "ERC20 total ether sent                         829    8.423941\n",
            "ERC20 total Ether sent contract                829    8.423941\n",
            "ERC20 uniq sent addr                           829    8.423941\n",
            "ERC20 uniq rec addr                            829    8.423941\n",
            "ERC20 uniq sent addr.1                         829    8.423941\n",
            "ERC20 uniq rec contract addr                   829    8.423941\n",
            "ERC20 avg time between sent tnx                829    8.423941\n",
            "ERC20 avg time between rec tnx                 829    8.423941\n",
            "ERC20 avg time between rec 2 tnx               829    8.423941\n",
            "ERC20 avg time between contract tnx            829    8.423941\n",
            "ERC20 min val rec                              829    8.423941\n",
            "ERC20 max val rec                              829    8.423941\n",
            "ERC20 avg val rec                              829    8.423941\n",
            "ERC20 min val sent                             829    8.423941\n",
            "ERC20 max val sent                             829    8.423941\n",
            "ERC20 avg val sent                             829    8.423941\n",
            "ERC20 min val sent contract                    829    8.423941\n",
            "ERC20 max val sent contract                    829    8.423941\n",
            "ERC20 avg val sent contract                    829    8.423941\n",
            "ERC20 uniq sent token name                     829    8.423941\n",
            "ERC20 uniq rec token name                      829    8.423941\n",
            "ERC20 most sent token type                    2697   27.405751\n",
            "ERC20_most_rec_token_type                      871    8.850727\n",
            "\n",
            "Class Distribution (FLAG):\n",
            "FLAG\n",
            "0    7662\n",
            "1    2179\n",
            "Name: count, dtype: int64\n",
            "Fraud Percentage: 22.14%\n",
            "Clean Percentage: 77.86%\n",
            "Imbalance Ratio: 3.52:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDATA PREPROCESSING\")\n",
        "\n",
        "# 1. Separate features (X) and target (y)\n",
        "X = df.drop(columns=[fraud_col], errors='ignore')\n",
        "\n",
        "# 2. FIX: Explicitly drop non-predictive/ID columns (Unnamed: 0, Index, Address)\n",
        "columns_to_drop = ['Unnamed: 0', 'Index', 'Address']\n",
        "X = X.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# 3. Continue with the rest of the preprocessing steps\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(f\"Numeric Features ({len(numeric_cols)}): {numeric_cols[:5]}{'...' if len(numeric_cols) > 5 else ''}\")\n",
        "print(f\"Categorical Features ({len(categorical_cols)}): {categorical_cols}\")\n",
        "\n",
        "if categorical_cols:\n",
        "    print(\"Encoding categorical features...\")\n",
        "    le = LabelEncoder()\n",
        "    # Handle the two remaining categorical features with Label Encoding\n",
        "    for col in [' ERC20 most sent token type', ' ERC20_most_rec_token_type']:\n",
        "        if col in X.columns: # Ensure only the relevant categoricals are processed\n",
        "            X[col] = le.fit_transform(X[col].astype(str))\n",
        "    print(\"Categorical encoding complete!\")\n",
        "\n",
        "# Handle missing values\n",
        "if X.isnull().sum().sum() > 0:\n",
        "    print(\"Handling missing values with median imputation...\")\n",
        "    X = X.fillna(X.median())\n",
        "    print(\"Missing values filled!\")\n",
        "\n",
        "# Final check\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "print(f\"Final feature matrix shape: {X.shape}\")"
      ],
      "metadata": {
        "id": "MWQpV0OKBlgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b916ef-4060-4e8d-ed97-86f278d68ad2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DATA PREPROCESSING\n",
            "Numeric Features (45): ['Avg min between sent tnx', 'Avg min between received tnx', 'Time Diff between first and last (Mins)', 'Sent tnx', 'Received Tnx']...\n",
            "Categorical Features (2): [' ERC20 most sent token type', ' ERC20_most_rec_token_type']\n",
            "Encoding categorical features...\n",
            "Categorical encoding complete!\n",
            "Handling missing values with median imputation...\n",
            "Missing values filled!\n",
            "Final feature matrix shape: (9841, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFEATURE SELECTION\")\n",
        "print(\"Computing initial feature correlations and importance...\")\n",
        "\n",
        "X_temp = X.copy()\n",
        "y_temp = y.copy()\n",
        "\n",
        "X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "scaler_temp = StandardScaler()\n",
        "X_train_temp_scaled = scaler_temp.fit_transform(X_train_temp)\n",
        "\n",
        "imbalance_ratio_val = (y_train_temp == 0).sum() / max((y_train_temp == 1).sum(), 1)\n",
        "\n",
        "temp_model = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=imbalance_ratio_val,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "temp_model.fit(X_train_temp_scaled, y_train_temp)\n",
        "\n",
        "feature_importance_initial = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': temp_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "importance_threshold = 0.01\n",
        "selected_features = feature_importance_initial[\n",
        "    feature_importance_initial['Importance'] >= importance_threshold\n",
        "]['Feature'].tolist()\n",
        "\n",
        "print(f\"Features selected (importance >= {importance_threshold}): {len(selected_features)} out of {len(X.columns)}\")\n",
        "print(\"\\nTop 15 Selected Features:\")\n",
        "print(feature_importance_initial.head(15).to_string(index=False))\n",
        "\n",
        "X = X[selected_features]\n",
        "print(f\"\\nReduced feature matrix shape: {X.shape}\")"
      ],
      "metadata": {
        "id": "MiUeSGxlB2wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d063c119-f3d1-40c0-cc47-dc979d71fc03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FEATURE SELECTION\n",
            "Computing initial feature correlations and importance...\n",
            "Features selected (importance >= 0.01): 10 out of 47\n",
            "\n",
            "Top 15 Selected Features:\n",
            "                                             Feature  Importance\n",
            "                                    Total ERC20 tnxs    0.469935\n",
            "             Time Diff between first and last (Mins)    0.137923\n",
            "                           ERC20_most_rec_token_type    0.085919\n",
            "                          ERC20 most sent token type    0.081115\n",
            "                                  ERC20 avg val sent    0.028989\n",
            "                                ERC20 uniq sent addr    0.024042\n",
            "                          ERC20 total Ether received    0.021083\n",
            "                                   ERC20 max val rec    0.015976\n",
            "                                    avg val received    0.011557\n",
            "                      Unique Received From Addresses    0.010864\n",
            "                                   ERC20 min val rec    0.009879\n",
            "                                 total ether balance    0.009633\n",
            "                        Avg min between received tnx    0.009316\n",
            "                                            Sent tnx    0.009243\n",
            "total transactions (including tnx to create contract    0.009157\n",
            "\n",
            "Reduced feature matrix shape: (9841, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGENERATING VISUALIZATIONS\")\n",
        "\n",
        "n_features_to_plot = min(6, len(X.columns))\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Feature Distributions', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, col in enumerate(X.columns[:n_features_to_plot]):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "    ax.hist(X[col], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    ax.set_title(f'{col}', fontweight='bold')\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: feature_distributions.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"Generating correlation heatmap...\")\n",
        "plt.figure(figsize=(14, 12))\n",
        "correlation_matrix = X.corr()\n",
        "\n",
        "if len(X.columns) > 20:\n",
        "    top_features = X.var().nlargest(20).index\n",
        "    correlation_matrix = X[top_features].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=0.5, cbar_kws={'label': 'Correlation'})\n",
        "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: correlation_heatmap.png\")\n",
        "plt.close()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "class_counts = y.value_counts()\n",
        "axes[0].bar(['Clean', 'Fraud'], class_counts.values, color=['green', 'red'], alpha=0.7)\n",
        "axes[0].set_ylabel('Count', fontweight='bold')\n",
        "axes[0].set_title('Class Distribution', fontweight='bold')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "axes[1].pie(class_counts.values, labels=['Clean', 'Fraud'], autopct='%1.2f%%',\n",
        "            colors=['green', 'red'], startangle=90)\n",
        "axes[1].set_title('Class Proportion', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: class_distribution.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "LFdG2hCoB7p0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1064d347-8817-492a-e70f-103caf9d38ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GENERATING VISUALIZATIONS\n",
            "Saved: feature_distributions.png\n",
            "Generating correlation heatmap...\n",
            "Saved: correlation_heatmap.png\n",
            "Saved: class_distribution.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTRAIN/TEST SPLIT\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
        "print(f\"Clean: {(y_train == 0).sum():,} | Fraud: {(y_train == 1).sum():,}\")\n",
        "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
        "print(f\"Clean: {(y_test == 0).sum():,} | Fraud: {(y_test == 1).sum():,}\")\n",
        "\n",
        "print(\"\\nNormalizing features with StandardScaler...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Feature scaling complete!\")"
      ],
      "metadata": {
        "id": "bL58Of3KCBE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ef6d20-226c-42da-d0b9-1461c427b5bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAIN/TEST SPLIT\n",
            "Training set: 6,888 samples\n",
            "Clean: 5,363 | Fraud: 1,525\n",
            "Test set: 2,953 samples\n",
            "Clean: 2,299 | Fraud: 654\n",
            "\n",
            "Normalizing features with StandardScaler...\n",
            "Feature scaling complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMODEL TRAINING - XGBOOST\")\n",
        "\n",
        "imbalance_ratio = (y_train == 0).sum() / max((y_train == 1).sum(), 1)\n",
        "print(f\"Imbalance Ratio: {imbalance_ratio:.2f}\")\n",
        "print(f\"Using scale_pos_weight: {imbalance_ratio:.2f}\")\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.03,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=imbalance_ratio,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "print(\"\\nPerforming 5-fold cross-validation...\")\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(xgb_model, X_train_scaled, y_train, cv=cv, scoring='f1')\n",
        "print(f\"Cross-validation F1 scores: {cv_scores}\")\n",
        "print(f\"Mean F1 Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "\n",
        "print(\"\\nTraining final model on full training set...\")\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "id": "O1ZXlu0QCGer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d92528-c3cb-438d-e2aa-f2ca507dbe54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL TRAINING - XGBOOST\n",
            "Imbalance Ratio: 3.52\n",
            "Using scale_pos_weight: 3.52\n",
            "\n",
            "Performing 5-fold cross-validation...\n",
            "Cross-validation F1 scores: [0.98013245 0.9785832  0.98507463 0.97712418 0.97385621]\n",
            "Mean F1 Score: 0.9790 (+/- 0.0037)\n",
            "\n",
            "Training final model on full training set...\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPREDICTIONS AND SCORING\")\n",
        "\n",
        "y_pred = xgb_model.predict(X_test_scaled)\n",
        "y_pred_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "fraud_risk_rating = (1 - y_pred_proba) * 9 + 1\n",
        "fraud_risk_rating = np.round(fraud_risk_rating, 1)\n",
        "\n",
        "print(f\"Prediction Statistics:\")\n",
        "print(f\"Predicted Fraud: {y_pred.sum():,} ({y_pred.sum() / len(y_pred) * 100:.2f}%)\")\n",
        "print(f\"Predicted Clean: {(y_pred == 0).sum():,} ({(y_pred == 0).sum() / len(y_pred) * 100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nFraud Probability Statistics:\")\n",
        "print(f\"Min: {y_pred_proba.min():.4f}\")\n",
        "print(f\"Max: {y_pred_proba.max():.4f}\")\n",
        "print(f\"Mean: {y_pred_proba.mean():.4f}\")\n",
        "print(f\"Median: {np.median(y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "id": "2E-XInT4CJrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed380ee2-a9cc-4134-913b-0f3a6fc8cfb1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PREDICTIONS AND SCORING\n",
            "Prediction Statistics:\n",
            "Predicted Fraud: 652 (22.08%)\n",
            "Predicted Clean: 2,301 (77.92%)\n",
            "\n",
            "Fraud Probability Statistics:\n",
            "Min: 0.0002\n",
            "Max: 0.9997\n",
            "Mean: 0.2244\n",
            "Median: 0.0013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMODEL EVALUATION\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"Performance Metrics:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"                 Predicted\")\n",
        "print(f\"              Clean  Fraud\")\n",
        "print(f\"Actual Clean  {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
        "print(f\"       Fraud  {cm[1,0]:5d}  {cm[1,1]:5d}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred,\n",
        "                            target_names=['Clean', 'Fraud'],\n",
        "                            zero_division=0))"
      ],
      "metadata": {
        "id": "1IhYfQbsCM7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5aae2bc-c161-44c5-fa2b-539ab1fb93b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL EVALUATION\n",
            "Performance Metrics:\n",
            "Accuracy:  0.9925\n",
            "Precision: 0.9847\n",
            "Recall:    0.9817\n",
            "F1-Score:  0.9832\n",
            "ROC-AUC:   0.9994\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "              Clean  Fraud\n",
            "Actual Clean   2289     10\n",
            "       Fraud     12    642\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Clean       0.99      1.00      1.00      2299\n",
            "       Fraud       0.98      0.98      0.98       654\n",
            "\n",
            "    accuracy                           0.99      2953\n",
            "   macro avg       0.99      0.99      0.99      2953\n",
            "weighted avg       0.99      0.99      0.99      2953\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFEATURE IMPORTANCE ANALYSIS\")\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': xgb_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"Top 10 Most Important Features:\")\n",
        "print(feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = feature_importance.head(20)\n",
        "plt.barh(range(len(top_features)), top_features['Importance'], color='steelblue')\n",
        "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "plt.xlabel('Importance Score', fontweight='bold', fontsize=12)\n",
        "plt.ylabel('Features', fontweight='bold', fontsize=12)\n",
        "plt.title('Top 20 Feature Importances - XGBoost', fontweight='bold', fontsize=14)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\nSaved: feature_importance.png\")\n",
        "plt.close()\n",
        "\n",
        "xgb.plot_importance(xgb_model, max_num_features=10, importance_type='weight')\n",
        "plt.title(\"Top Features Driving Fraud Predictions\", fontweight='bold', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig('xgboost_feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: xgboost_feature_importance.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "zvpzzDekCQVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a7a17a-1552-4fbe-e98a-898ebde2d11e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FEATURE IMPORTANCE ANALYSIS\n",
            "Top 10 Most Important Features:\n",
            "                                Feature  Importance\n",
            "                       Total ERC20 tnxs    0.318866\n",
            "              ERC20_most_rec_token_type    0.225169\n",
            "             ERC20 most sent token type    0.178981\n",
            "Time Diff between first and last (Mins)    0.118817\n",
            "                   ERC20 uniq sent addr    0.042051\n",
            "                      ERC20 max val rec    0.033926\n",
            "         Unique Received From Addresses    0.028763\n",
            "                     ERC20 avg val sent    0.022735\n",
            "                       avg val received    0.020464\n",
            "             ERC20 total Ether received    0.010228\n",
            "\n",
            "Saved: feature_importance.png\n",
            "Saved: xgboost_feature_importance.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGENERATING RESULT VISUALIZATIONS\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=['Clean', 'Fraud'],\n",
        "            yticklabels=['Clean', 'Fraud'])\n",
        "plt.title('Confusion Matrix', fontweight='bold', fontsize=14)\n",
        "plt.ylabel('Actual Label', fontweight='bold', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontweight='bold', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: confusion_matrix.png\")\n",
        "plt.close()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "axes[0].hist(y_pred_proba[y_test == 0], bins=50, alpha=0.7, label='Clean', color='green')\n",
        "axes[0].hist(y_pred_proba[y_test == 1], bins=50, alpha=0.7, label='Fraud', color='red')\n",
        "axes[0].set_xlabel('Fraud Probability', fontweight='bold')\n",
        "axes[0].set_ylabel('Frequency', fontweight='bold')\n",
        "axes[0].set_title('Fraud Probability Distribution', fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].hist(fraud_risk_rating[y_test == 0], bins=50, alpha=0.7, label='Clean', color='green')\n",
        "axes[1].hist(fraud_risk_rating[y_test == 1], bins=50, alpha=0.7, label='Fraud', color='red')\n",
        "axes[1].set_xlabel('Fraud Risk Rating (1-10)', fontweight='bold')\n",
        "axes[1].set_ylabel('Frequency', fontweight='bold')\n",
        "axes[1].set_title('Fraud Risk Rating Distribution', fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fraud_probability_distribution.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: fraud_probability_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "         label=f'XGBoost (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
        "         label='Random Classifier (AUC = 0.50)')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=12)\n",
        "plt.title('ROC Curve - XGBoost Fraud Detection', fontweight='bold', fontsize=14)\n",
        "plt.legend(loc=\"lower right\", fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: roc_curve.png\")\n",
        "plt.close()\n",
        "\n",
        "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "pr_auc = auc(recall_vals, precision_vals)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(recall_vals, precision_vals, color='darkorange', lw=2,\n",
        "         label=f'XGBoost (AUC = {pr_auc:.4f})')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall', fontweight='bold', fontsize=12)\n",
        "plt.ylabel('Precision', fontweight='bold', fontsize=12)\n",
        "plt.title('Precision-Recall Curve - XGBoost', fontweight='bold', fontsize=14)\n",
        "plt.legend(loc=\"lower left\", fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: precision_recall_curve.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "Zy5TEmgwCTvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf534f9-db57-4fd5-f53a-6a11d78c95ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GENERATING RESULT VISUALIZATIONS\n",
            "Saved: confusion_matrix.png\n",
            "Saved: fraud_probability_distribution.png\n",
            "Saved: roc_curve.png\n",
            "Saved: precision_recall_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFINAL RESULTS OUTPUT\")\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Transaction_Index': X_test.index,\n",
        "    'Fraud_Probability': y_pred_proba,\n",
        "    'Prediction': ['Fraud' if p == 1 else 'Clean' for p in y_pred],\n",
        "    'Fraud_Risk_Rating_1_10': fraud_risk_rating,\n",
        "    'Actual_Label': ['Fraud' if y == 1 else 'Clean' for y in y_test],\n",
        "    'Correct_Prediction': y_pred == y_test\n",
        "})\n",
        "\n",
        "results_df = results_df.sort_values('Fraud_Probability', ascending=False)\n",
        "\n",
        "print(\"\\nSample Results (Top 10 Highest Risk):\")\n",
        "print(results_df.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nSample Results (Top 10 Lowest Risk):\")\n",
        "print(results_df.tail(10).to_string(index=False))\n",
        "\n",
        "results_df.to_csv('fraud_detection_results_xgboost.csv', index=False)\n",
        "print(\"\\nFull results saved to: fraud_detection_results_xgboost.csv\")\n",
        "\n",
        "feature_importance.to_csv('feature_importance_xgboost.csv', index=False)\n",
        "print(\"Feature importance saved to: feature_importance_xgboost.csv\")\n",
        "\n",
        "print(\"\\nSUMMARY\")\n",
        "print(f\"Total transactions analyzed: {len(results_df):,}\")\n",
        "print(f\"Flagged as fraud: {(y_pred == 1).sum():,} ({(y_pred == 1).sum() / len(y_pred) * 100:.2f}%)\")\n",
        "print(f\"Flagged as clean: {(y_pred == 0).sum():,} ({(y_pred == 0).sum() / len(y_pred) * 100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nModel Performance Summary:\")\n",
        "print(f\"Accuracy:  {accuracy:.2%}\")\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall:    {recall:.2%}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "print(f\"Specificity: {specificity:.2%}\")\n",
        "\n",
        "if tp + fn > 0:\n",
        "    fraud_detection_rate = tp / (tp + fn)\n",
        "    print(f\"Fraud Detection Rate: {fraud_detection_rate:.2%}\")\n",
        "\n",
        "print(\"\\nFRAUD DETECTION ANALYSIS COMPLETE!\")\n",
        "print(\"Generated Files:\")\n",
        "print(\"feature_distributions.png\")\n",
        "print(\"correlation_heatmap.png\")\n",
        "print(\"class_distribution.png\")\n",
        "print(\"feature_importance.png\")\n",
        "print(\"xgboost_feature_importance.png\")\n",
        "print(\"confusion_matrix.png\")\n",
        "print(\"fraud_probability_distribution.png\")\n",
        "print(\"roc_curve.png\")\n",
        "print(\"precision_recall_curve.png\")\n",
        "print(\"fraud_detection_results_xgboost.csv\")\n",
        "print(\"feature_importance_xgboost.csv\")"
      ],
      "metadata": {
        "id": "-y1gT1PrCX-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3790dd57-56fd-4441-8c26-ce034e722e80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL RESULTS OUTPUT\n",
            "\n",
            "Sample Results (Top 10 Highest Risk):\n",
            " Transaction_Index  Fraud_Probability Prediction  Fraud_Risk_Rating_1_10 Actual_Label  Correct_Prediction\n",
            "              7682           0.999715      Fraud                     1.0        Fraud                True\n",
            "              9261           0.999715      Fraud                     1.0        Fraud                True\n",
            "              7816           0.999712      Fraud                     1.0        Fraud                True\n",
            "              8797           0.999712      Fraud                     1.0        Fraud                True\n",
            "              9097           0.999709      Fraud                     1.0        Fraud                True\n",
            "              9147           0.999709      Fraud                     1.0        Fraud                True\n",
            "              8590           0.999707      Fraud                     1.0        Fraud                True\n",
            "              9282           0.999706      Fraud                     1.0        Fraud                True\n",
            "              8289           0.999705      Fraud                     1.0        Fraud                True\n",
            "              8736           0.999702      Fraud                     1.0        Fraud                True\n",
            "\n",
            "Sample Results (Top 10 Lowest Risk):\n",
            " Transaction_Index  Fraud_Probability Prediction  Fraud_Risk_Rating_1_10 Actual_Label  Correct_Prediction\n",
            "               963           0.000238      Clean                    10.0        Clean                True\n",
            "              1248           0.000238      Clean                    10.0        Clean                True\n",
            "              3030           0.000238      Clean                    10.0        Clean                True\n",
            "              5217           0.000238      Clean                    10.0        Clean                True\n",
            "              2026           0.000236      Clean                    10.0        Clean                True\n",
            "              6389           0.000236      Clean                    10.0        Clean                True\n",
            "              6673           0.000231      Clean                    10.0        Clean                True\n",
            "              3445           0.000231      Clean                    10.0        Clean                True\n",
            "              6638           0.000231      Clean                    10.0        Clean                True\n",
            "              4111           0.000231      Clean                    10.0        Clean                True\n",
            "\n",
            "Full results saved to: fraud_detection_results_xgboost.csv\n",
            "Feature importance saved to: feature_importance_xgboost.csv\n",
            "\n",
            "SUMMARY\n",
            "Total transactions analyzed: 2,953\n",
            "Flagged as fraud: 652 (22.08%)\n",
            "Flagged as clean: 2,301 (77.92%)\n",
            "\n",
            "Model Performance Summary:\n",
            "Accuracy:  99.25%\n",
            "Precision: 98.47%\n",
            "Recall:    98.17%\n",
            "F1-Score:  0.9832\n",
            "ROC-AUC:   0.9994\n",
            "Specificity: 99.57%\n",
            "Fraud Detection Rate: 98.17%\n",
            "\n",
            "FRAUD DETECTION ANALYSIS COMPLETE!\n",
            "Generated Files:\n",
            "feature_distributions.png\n",
            "correlation_heatmap.png\n",
            "class_distribution.png\n",
            "feature_importance.png\n",
            "xgboost_feature_importance.png\n",
            "confusion_matrix.png\n",
            "fraud_probability_distribution.png\n",
            "roc_curve.png\n",
            "precision_recall_curve.png\n",
            "fraud_detection_results_xgboost.csv\n",
            "feature_importance_xgboost.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 🔍 TO TEST USER INPUTS\n",
        "# ============================\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"🧠 FRAUD PREDICTION ON NEW DATASET\")\n",
        "\n",
        "try:\n",
        "    # Load the new dataset\n",
        "    new_df = pd.read_csv(\"mydata.csv\")\n",
        "\n",
        "    print(f\"\\n✅ Dataset loaded successfully!\")\n",
        "    print(f\"   Rows: {new_df.shape[0]:,} | Columns: {new_df.shape[1]}\")\n",
        "    print(\"\\nFirst 3 rows of your data:\")\n",
        "    print(new_df.head(3))\n",
        "\n",
        "    # Check for 'FLAG' column (actual labels)\n",
        "    has_flag = 'FLAG' in new_df.columns\n",
        "    if has_flag:\n",
        "        print(\"\\n⚠️ FLAG column detected — removing for prediction.\")\n",
        "        actual_labels = new_df['FLAG'].copy()\n",
        "        new_df = new_df.drop(columns=['FLAG'])\n",
        "    else:\n",
        "        actual_labels = None\n",
        "        print(\"\\nNo FLAG column found — assuming unlabeled test data.\")\n",
        "\n",
        "    # Save identifying info (if any)\n",
        "    original_indices = new_df.index.copy()\n",
        "    addresses = new_df['Address'].copy() if 'Address' in new_df.columns else None\n",
        "\n",
        "    # Preprocessing (same as training)\n",
        "    print(\"\\n🧹 PREPROCESSING NEW DATA\")\n",
        "\n",
        "    # Drop ID-like columns\n",
        "    cols_to_drop = ['Unnamed: 0', 'Index', 'Address']\n",
        "    new_X = new_df.drop(columns=[c for c in cols_to_drop if c in new_df.columns], errors='ignore')\n",
        "    print(\"   Removed identifier columns\")\n",
        "\n",
        "    # Encode categorical columns\n",
        "    cat_cols = new_X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    if cat_cols:\n",
        "        print(f\"   Encoding {len(cat_cols)} categorical features...\")\n",
        "        le = LabelEncoder()\n",
        "        for c in cat_cols:\n",
        "            new_X[c] = le.fit_transform(new_X[c].astype(str))\n",
        "\n",
        "    # Handle missing values\n",
        "    if new_X.isnull().sum().sum() > 0:\n",
        "        print(\"   Filling missing values with median...\")\n",
        "        new_X = new_X.fillna(new_X.median())\n",
        "\n",
        "    # Keep only numeric features\n",
        "    new_X = new_X.select_dtypes(include=[np.number])\n",
        "\n",
        "    # Match training features\n",
        "    print(f\"\\n📊 Aligning with {len(selected_features)} training features...\")\n",
        "    missing_feats = [f for f in selected_features if f not in new_X.columns]\n",
        "    if missing_feats:\n",
        "        print(f\"   Missing features: {missing_feats}\")\n",
        "        for f in missing_feats:\n",
        "            new_X[f] = 0\n",
        "    new_X = new_X[selected_features]\n",
        "\n",
        "    print(f\"   Final feature matrix: {new_X.shape}\")\n",
        "\n",
        "    # Scale features using training scaler\n",
        "    print(\"⚖️ Scaling features...\")\n",
        "    new_X_scaled = scaler.transform(new_X)\n",
        "\n",
        "    # Predict\n",
        "    print(\"\\n🚀 MAKING PREDICTIONS...\")\n",
        "    new_preds = xgb_model.predict(new_X_scaled)\n",
        "    new_proba = xgb_model.predict_proba(new_X_scaled)[:, 1]\n",
        "\n",
        "    # Compute risk rating\n",
        "    risk_rating = np.round((1 - new_proba) * 9 + 1, 1)\n",
        "\n",
        "    # Compile results\n",
        "    results_new = pd.DataFrame({\n",
        "        'Transaction_Index': original_indices,\n",
        "        'Fraud_Probability': new_proba,\n",
        "        'Prediction': ['Fraud' if p == 1 else 'Clean' for p in new_preds],\n",
        "        'Fraud_Risk_Rating_1_10': risk_rating,\n",
        "        'Confidence': np.maximum(new_proba, 1 - new_proba) * 100\n",
        "    })\n",
        "\n",
        "    if addresses is not None:\n",
        "        results_new.insert(1, 'Address', addresses.values)\n",
        "\n",
        "    if actual_labels is not None:\n",
        "        results_new['Actual_Label'] = ['Fraud' if y == 1 else 'Clean' for y in actual_labels]\n",
        "        results_new['Correct_Prediction'] = new_preds == actual_labels.values\n",
        "\n",
        "    results_new = results_new.sort_values('Fraud_Probability', ascending=False)\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n✅ PREDICTIONS COMPLETE\")\n",
        "    print(f\"Total Transactions: {len(new_preds):,}\")\n",
        "    print(f\"   Predicted Fraud: {(new_preds == 1).sum():,}\")\n",
        "    print(f\"   Predicted Clean: {(new_preds == 0).sum():,}\")\n",
        "\n",
        "    print(\"\\n📈 Probability Summary:\")\n",
        "    print(f\"   Min: {new_proba.min():.4f} | Max: {new_proba.max():.4f} | Mean: {new_proba.mean():.4f}\")\n",
        "\n",
        "    # If labeled, compute performance\n",
        "    if actual_labels is not None:\n",
        "        print(\"\\n🎯 PERFORMANCE ON NEW DATA (with labels)\")\n",
        "        acc = accuracy_score(actual_labels, new_preds)\n",
        "        prec = precision_score(actual_labels, new_preds, zero_division=0)\n",
        "        rec = recall_score(actual_labels, new_preds, zero_division=0)\n",
        "        f1 = f1_score(actual_labels, new_preds, zero_division=0)\n",
        "        roc = roc_auc_score(actual_labels, new_proba)\n",
        "        cm = confusion_matrix(actual_labels, new_preds)\n",
        "\n",
        "        print(f\"Accuracy:  {acc:.2%}\")\n",
        "        print(f\"Precision: {prec:.2%}\")\n",
        "        print(f\"Recall:    {rec:.2%}\")\n",
        "        print(f\"F1-Score:  {f1:.4f}\")\n",
        "        print(f\"ROC-AUC:   {roc:.4f}\")\n",
        "\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(cm)\n",
        "\n",
        "    # Categorize by risk\n",
        "    high = (new_proba >= 0.7).sum()\n",
        "    med = ((new_proba >= 0.3) & (new_proba < 0.7)).sum()\n",
        "    low = (new_proba < 0.3).sum()\n",
        "\n",
        "    print(\"\\nRISK CATEGORIES:\")\n",
        "    print(f\"   HIGH (≥70%):  {high:,}\")\n",
        "    print(f\"   MEDIUM (30–70%): {med:,}\")\n",
        "    print(f\"   LOW (<30%):   {low:,}\")\n",
        "\n",
        "    # Save output\n",
        "    results_new.to_csv(\"new_fraud_predictions.csv\", index=False)\n",
        "    print(\"\\n💾 Results saved as: new_fraud_predictions.csv\")\n",
        "\n",
        "    # Visualization\n",
        "    print(\"\\n📊 Generating visualizations...\")\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    axes[0].hist(new_proba, bins=50, color='skyblue', edgecolor='black')\n",
        "    axes[0].axvline(0.5, color='red', linestyle='--')\n",
        "    axes[0].set_title(\"Fraud Probability Distribution\")\n",
        "\n",
        "    axes[1].hist(risk_rating, bins=30, color='orange', edgecolor='black')\n",
        "    axes[1].set_title(\"Fraud Risk Rating (1=High Risk)\")\n",
        "\n",
        "    pred_counts = pd.Series(new_preds).value_counts()\n",
        "    axes[2].bar(['Clean', 'Fraud'], [pred_counts.get(0,0), pred_counts.get(1,0)], color=['green','red'])\n",
        "    axes[2].set_title(\"Prediction Distribution\")\n",
        "\n",
        "    axes[3].bar(['Low Risk', 'Medium Risk', 'High Risk'], [low, med, high], color=['green','orange','red'])\n",
        "    axes[3].set_title(\"Risk Category Distribution\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"new_data_predictions_analysis.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    print(\"   ✅ Saved: new_data_predictions_analysis.png\")\n",
        "\n",
        "    if actual_labels is not None:\n",
        "        plt.figure(figsize=(6,5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Clean','Fraud'], yticklabels=['Clean','Fraud'])\n",
        "        plt.title(\"Confusion Matrix - New Data\")\n",
        "        plt.savefig(\"new_data_confusion_matrix.png\", dpi=300)\n",
        "        plt.close()\n",
        "        print(\"   ✅ Saved: new_data_confusion_matrix.png\")\n",
        "\n",
        "    print(\"\\n🚨 RECOMMENDATION:\")\n",
        "    if high > 0:\n",
        "        print(f\"   ⚠️ {high} HIGH-RISK transactions — review immediately!\")\n",
        "    elif med > 0:\n",
        "        print(f\"   🟠 {med} medium-risk transactions — monitor closely.\")\n",
        "    else:\n",
        "        print(\"   ✅ All transactions appear low-risk. Routine monitoring recommended.\")\n",
        "\n",
        "    print(\"\\nFRAUD PREDICTION COMPLETE ✅\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERROR: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "uZtMO0dOYIgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db03719c-a7b1-4dc2-8c5b-674fadbc6376"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 FRAUD PREDICTION ON NEW DATASET\n",
            "\n",
            "✅ Dataset loaded successfully!\n",
            "   Rows: 10,000 | Columns: 51\n",
            "\n",
            "First 3 rows of your data:\n",
            "   Unnamed: 0  Index                                     Address  FLAG  \\\n",
            "0           0      1  0xcea1bee6387add3cf4f5ec054c028185bbd5d4fe     1   \n",
            "1           1      2  0xeb71ffd67842707dd7763011edba9b55b8ef217d     1   \n",
            "2           2      3  0x72506a6c1439c8bc12c0942bf3e35966edea724b     0   \n",
            "\n",
            "   Avg min between sent tnx  Avg min between received tnx  \\\n",
            "0                 21.543460                   1778.274159   \n",
            "1                 29.539527                     28.838359   \n",
            "2               8992.066377                  11413.995351   \n",
            "\n",
            "   Time Diff between first and last (Mins)  Sent tnx  Received Tnx  \\\n",
            "0                            106193.687448       200           264   \n",
            "1                            105590.597403       215           247   \n",
            "2                            563347.896832        56            83   \n",
            "\n",
            "   Number of Created Contracts  ...   ERC20 min val sent   ERC20 max val sent  \\\n",
            "0                           10  ...           312.707724         6.831099e+05   \n",
            "1                            9  ...          2516.779233         1.233734e+07   \n",
            "2                            0  ...           233.691547         5.527171e+05   \n",
            "\n",
            "    ERC20 avg val sent   ERC20 min val sent contract  \\\n",
            "0         1.170159e+06                           0.0   \n",
            "1         3.012109e+05                           0.0   \n",
            "2         1.340407e+04                           0.0   \n",
            "\n",
            "    ERC20 max val sent contract   ERC20 avg val sent contract  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "\n",
            "    ERC20 uniq sent token name   ERC20 uniq rec token name  \\\n",
            "0                         14.0                        26.0   \n",
            "1                          3.0                        21.0   \n",
            "2                          3.0                         7.0   \n",
            "\n",
            "    ERC20 most sent token type   ERC20_most_rec_token_type  \n",
            "0                        FLOKI                        PEPE  \n",
            "1                         SHIB                        FAKE  \n",
            "2                         USDT                        AAVE  \n",
            "\n",
            "[3 rows x 51 columns]\n",
            "\n",
            "⚠️ FLAG column detected — removing for prediction.\n",
            "\n",
            "🧹 PREPROCESSING NEW DATA\n",
            "   Removed identifier columns\n",
            "   Encoding 2 categorical features...\n",
            "   Filling missing values with median...\n",
            "\n",
            "📊 Aligning with 10 training features...\n",
            "   Final feature matrix: (10000, 10)\n",
            "⚖️ Scaling features...\n",
            "\n",
            "🚀 MAKING PREDICTIONS...\n",
            "\n",
            "✅ PREDICTIONS COMPLETE\n",
            "Total Transactions: 10,000\n",
            "   Predicted Fraud: 4,132\n",
            "   Predicted Clean: 5,868\n",
            "\n",
            "📈 Probability Summary:\n",
            "   Min: 0.0008 | Max: 0.9955 | Mean: 0.3821\n",
            "\n",
            "🎯 PERFORMANCE ON NEW DATA (with labels)\n",
            "Accuracy:  75.40%\n",
            "Precision: 86.79%\n",
            "Recall:    65.20%\n",
            "F1-Score:  0.7446\n",
            "ROC-AUC:   0.8728\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3954  546]\n",
            " [1914 3586]]\n",
            "\n",
            "RISK CATEGORIES:\n",
            "   HIGH (≥70%):  2,627\n",
            "   MEDIUM (30–70%): 2,570\n",
            "   LOW (<30%):   4,803\n",
            "\n",
            "💾 Results saved as: new_fraud_predictions.csv\n",
            "\n",
            "📊 Generating visualizations...\n",
            "   ✅ Saved: new_data_predictions_analysis.png\n",
            "   ✅ Saved: new_data_confusion_matrix.png\n",
            "\n",
            "🚨 RECOMMENDATION:\n",
            "   ⚠️ 2627 HIGH-RISK transactions — review immediately!\n",
            "\n",
            "FRAUD PREDICTION COMPLETE ✅\n"
          ]
        }
      ]
    }
  ]
}