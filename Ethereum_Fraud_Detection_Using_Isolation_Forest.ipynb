{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# IMPORTING LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "LGjdd4k_9aUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set style for better visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ],
      "metadata": {
        "id": "XpcKRzih9eWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING DATASET\n",
        "print(\"=\" * 80)\n",
        "print(\"ETHEREUM FRAUD DETECTION - ISOLATION FOREST\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/transaction_dataset.csv\")\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"   Rows: {df.shape[0]:,} | Columns: {df.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS0qBjNK9jsS",
        "outputId": "e8d4491b-f8f0-482b-81be-b518714bce9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ETHEREUM FRAUD DETECTION - ISOLATION FOREST\n",
            "================================================================================\n",
            "Dataset Shape: (9841, 51)\n",
            "   Rows: 9,841 | Columns: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Display basic info\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"First Few Rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"Statistical Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing Values:\")\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing,\n",
        "    'Percentage': missing_pct\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "if missing.sum() == 0:\n",
        "    print(\"No missing values found!\")\n",
        "\n",
        "# Check class distribution (assuming 'FLAG' column indicates fraud)\n",
        "# Common column names: 'FLAG', 'Class', 'isFraud', 'Fraud'\n",
        "fraud_col = None\n",
        "for col in ['FLAG', 'Class', 'isFraud', 'Fraud', 'is_fraud']:\n",
        "    if col in df.columns:\n",
        "        fraud_col = col\n",
        "        break\n",
        "\n",
        "if fraud_col:\n",
        "    print(f\"Class Distribution ({fraud_col}):\")\n",
        "    class_dist = df[fraud_col].value_counts()\n",
        "    print(class_dist)\n",
        "    print(f\"Fraud Percentage: {(class_dist.get(1, 0) / len(df)) * 100:.2f}%\")\n",
        "    print(f\"Clean Percentage: {(class_dist.get(0, 0) / len(df)) * 100:.2f}%\")\n",
        "\n",
        "    # Store the target variable\n",
        "    y = df[fraud_col]\n",
        "else:\n",
        "    print(\"Warning: Could not find fraud label column!\")\n",
        "    print(\"Available columns:\", df.columns.tolist())\n",
        "    # Create dummy target for demonstration\n",
        "    y = pd.Series([0] * len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IBaky3F9sIf",
        "outputId": "4d15c880-d79c-45c4-b425-b25583acf0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPLORATORY DATA ANALYSIS\n",
            "================================================================================\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9841 entries, 0 to 9840\n",
            "Data columns (total 51 columns):\n",
            " #   Column                                                Non-Null Count  Dtype  \n",
            "---  ------                                                --------------  -----  \n",
            " 0   Unnamed: 0                                            9841 non-null   int64  \n",
            " 1   Index                                                 9841 non-null   int64  \n",
            " 2   Address                                               9841 non-null   object \n",
            " 3   FLAG                                                  9841 non-null   int64  \n",
            " 4   Avg min between sent tnx                              9841 non-null   float64\n",
            " 5   Avg min between received tnx                          9841 non-null   float64\n",
            " 6   Time Diff between first and last (Mins)               9841 non-null   float64\n",
            " 7   Sent tnx                                              9841 non-null   int64  \n",
            " 8   Received Tnx                                          9841 non-null   int64  \n",
            " 9   Number of Created Contracts                           9841 non-null   int64  \n",
            " 10  Unique Received From Addresses                        9841 non-null   int64  \n",
            " 11  Unique Sent To Addresses                              9841 non-null   int64  \n",
            " 12  min value received                                    9841 non-null   float64\n",
            " 13  max value received                                    9841 non-null   float64\n",
            " 14  avg val received                                      9841 non-null   float64\n",
            " 15  min val sent                                          9841 non-null   float64\n",
            " 16  max val sent                                          9841 non-null   float64\n",
            " 17  avg val sent                                          9841 non-null   float64\n",
            " 18  min value sent to contract                            9841 non-null   float64\n",
            " 19  max val sent to contract                              9841 non-null   float64\n",
            " 20  avg value sent to contract                            9841 non-null   float64\n",
            " 21  total transactions (including tnx to create contract  9841 non-null   int64  \n",
            " 22  total Ether sent                                      9841 non-null   float64\n",
            " 23  total ether received                                  9841 non-null   float64\n",
            " 24  total ether sent contracts                            9841 non-null   float64\n",
            " 25  total ether balance                                   9841 non-null   float64\n",
            " 26   Total ERC20 tnxs                                     9012 non-null   float64\n",
            " 27   ERC20 total Ether received                           9012 non-null   float64\n",
            " 28   ERC20 total ether sent                               9012 non-null   float64\n",
            " 29   ERC20 total Ether sent contract                      9012 non-null   float64\n",
            " 30   ERC20 uniq sent addr                                 9012 non-null   float64\n",
            " 31   ERC20 uniq rec addr                                  9012 non-null   float64\n",
            " 32   ERC20 uniq sent addr.1                               9012 non-null   float64\n",
            " 33   ERC20 uniq rec contract addr                         9012 non-null   float64\n",
            " 34   ERC20 avg time between sent tnx                      9012 non-null   float64\n",
            " 35   ERC20 avg time between rec tnx                       9012 non-null   float64\n",
            " 36   ERC20 avg time between rec 2 tnx                     9012 non-null   float64\n",
            " 37   ERC20 avg time between contract tnx                  9012 non-null   float64\n",
            " 38   ERC20 min val rec                                    9012 non-null   float64\n",
            " 39   ERC20 max val rec                                    9012 non-null   float64\n",
            " 40   ERC20 avg val rec                                    9012 non-null   float64\n",
            " 41   ERC20 min val sent                                   9012 non-null   float64\n",
            " 42   ERC20 max val sent                                   9012 non-null   float64\n",
            " 43   ERC20 avg val sent                                   9012 non-null   float64\n",
            " 44   ERC20 min val sent contract                          9012 non-null   float64\n",
            " 45   ERC20 max val sent contract                          9012 non-null   float64\n",
            " 46   ERC20 avg val sent contract                          9012 non-null   float64\n",
            " 47   ERC20 uniq sent token name                           9012 non-null   float64\n",
            " 48   ERC20 uniq rec token name                            9012 non-null   float64\n",
            " 49   ERC20 most sent token type                           7144 non-null   object \n",
            " 50   ERC20_most_rec_token_type                            8970 non-null   object \n",
            "dtypes: float64(39), int64(9), object(3)\n",
            "memory usage: 3.8+ MB\n",
            "None\n",
            "First Few Rows:\n",
            "   Unnamed: 0  Index                                     Address  FLAG  \\\n",
            "0           0      1  0x00009277775ac7d0d59eaad8fee3d10ac6c805e8     0   \n",
            "1           1      2  0x0002b44ddb1476db43c868bd494422ee4c136fed     0   \n",
            "2           2      3  0x0002bda54cb772d040f779e88eb453cac0daa244     0   \n",
            "3           3      4  0x00038e6ba2fd5c09aedb96697c8d7b8fa6632e5e     0   \n",
            "4           4      5  0x00062d1dd1afb6fb02540ddad9cdebfe568e0d89     0   \n",
            "\n",
            "   Avg min between sent tnx  Avg min between received tnx  \\\n",
            "0                    844.26                       1093.71   \n",
            "1                  12709.07                       2958.44   \n",
            "2                 246194.54                       2434.02   \n",
            "3                  10219.60                      15785.09   \n",
            "4                     36.61                      10707.77   \n",
            "\n",
            "   Time Diff between first and last (Mins)  Sent tnx  Received Tnx  \\\n",
            "0                                704785.63       721            89   \n",
            "1                               1218216.73        94             8   \n",
            "2                                516729.30         2            10   \n",
            "3                                397555.90        25             9   \n",
            "4                                382472.42      4598            20   \n",
            "\n",
            "   Number of Created Contracts  ...   ERC20 min val sent   ERC20 max val sent  \\\n",
            "0                            0  ...             0.000000         1.683100e+07   \n",
            "1                            0  ...             2.260809         2.260809e+00   \n",
            "2                            0  ...             0.000000         0.000000e+00   \n",
            "3                            0  ...           100.000000         9.029231e+03   \n",
            "4                            1  ...             0.000000         4.500000e+04   \n",
            "\n",
            "    ERC20 avg val sent   ERC20 min val sent contract  \\\n",
            "0        271779.920000                           0.0   \n",
            "1             2.260809                           0.0   \n",
            "2             0.000000                           0.0   \n",
            "3          3804.076893                           0.0   \n",
            "4         13726.659220                           0.0   \n",
            "\n",
            "    ERC20 max val sent contract   ERC20 avg val sent contract  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "3                           0.0                           0.0   \n",
            "4                           0.0                           0.0   \n",
            "\n",
            "    ERC20 uniq sent token name   ERC20 uniq rec token name  \\\n",
            "0                         39.0                        57.0   \n",
            "1                          1.0                         7.0   \n",
            "2                          0.0                         8.0   \n",
            "3                          1.0                        11.0   \n",
            "4                          6.0                        27.0   \n",
            "\n",
            "    ERC20 most sent token type   ERC20_most_rec_token_type  \n",
            "0                    Cofoundit                   Numeraire  \n",
            "1               Livepeer Token              Livepeer Token  \n",
            "2                          NaN                       XENON  \n",
            "3                       Raiden                       XENON  \n",
            "4                StatusNetwork                         EOS  \n",
            "\n",
            "[5 rows x 51 columns]\n",
            "Statistical Summary:\n",
            "        Unnamed: 0        Index         FLAG  Avg min between sent tnx  \\\n",
            "count  9841.000000  9841.000000  9841.000000               9841.000000   \n",
            "mean   4920.000000  1815.049893     0.221421               5086.878721   \n",
            "std    2840.996333  1222.621830     0.415224              21486.549974   \n",
            "min       0.000000     1.000000     0.000000                  0.000000   \n",
            "25%    2460.000000   821.000000     0.000000                  0.000000   \n",
            "50%    4920.000000  1641.000000     0.000000                 17.340000   \n",
            "75%    7380.000000  2601.000000     0.000000                565.470000   \n",
            "max    9840.000000  4729.000000     1.000000             430287.670000   \n",
            "\n",
            "       Avg min between received tnx  Time Diff between first and last (Mins)  \\\n",
            "count                   9841.000000                             9.841000e+03   \n",
            "mean                    8004.851184                             2.183333e+05   \n",
            "std                    23081.714801                             3.229379e+05   \n",
            "min                        0.000000                             0.000000e+00   \n",
            "25%                        0.000000                             3.169300e+02   \n",
            "50%                      509.770000                             4.663703e+04   \n",
            "75%                     5480.390000                             3.040710e+05   \n",
            "max                   482175.490000                             1.954861e+06   \n",
            "\n",
            "           Sent tnx  Received Tnx  Number of Created Contracts  \\\n",
            "count   9841.000000   9841.000000                  9841.000000   \n",
            "mean     115.931714    163.700945                     3.729702   \n",
            "std      757.226361    940.836550                   141.445583   \n",
            "min        0.000000      0.000000                     0.000000   \n",
            "25%        1.000000      1.000000                     0.000000   \n",
            "50%        3.000000      4.000000                     0.000000   \n",
            "75%       11.000000     27.000000                     0.000000   \n",
            "max    10000.000000  10000.000000                  9995.000000   \n",
            "\n",
            "       Unique Received From Addresses  ...   ERC20 max val rec  \\\n",
            "count                     9841.000000  ...        9.012000e+03   \n",
            "mean                        30.360939  ...        1.252524e+08   \n",
            "std                        298.621112  ...        1.053741e+10   \n",
            "min                          0.000000  ...        0.000000e+00   \n",
            "25%                          1.000000  ...        0.000000e+00   \n",
            "50%                          2.000000  ...        0.000000e+00   \n",
            "75%                          5.000000  ...        9.900000e+01   \n",
            "max                       9999.000000  ...        1.000000e+12   \n",
            "\n",
            "        ERC20 avg val rec   ERC20 min val sent   ERC20 max val sent  \\\n",
            "count        9.012000e+03         9.012000e+03         9.012000e+03   \n",
            "mean         4.346203e+06         1.174126e+04         1.303594e+07   \n",
            "std          2.141192e+08         1.053567e+06         1.179905e+09   \n",
            "min          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "25%          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "50%          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "75%          2.946467e+01         0.000000e+00         0.000000e+00   \n",
            "max          1.724181e+10         1.000000e+08         1.120000e+11   \n",
            "\n",
            "        ERC20 avg val sent   ERC20 min val sent contract  \\\n",
            "count         9.012000e+03                        9012.0   \n",
            "mean          6.318389e+06                           0.0   \n",
            "std           5.914764e+08                           0.0   \n",
            "min           0.000000e+00                           0.0   \n",
            "25%           0.000000e+00                           0.0   \n",
            "50%           0.000000e+00                           0.0   \n",
            "75%           0.000000e+00                           0.0   \n",
            "max           5.614756e+10                           0.0   \n",
            "\n",
            "        ERC20 max val sent contract   ERC20 avg val sent contract  \\\n",
            "count                        9012.0                        9012.0   \n",
            "mean                            0.0                           0.0   \n",
            "std                             0.0                           0.0   \n",
            "min                             0.0                           0.0   \n",
            "25%                             0.0                           0.0   \n",
            "50%                             0.0                           0.0   \n",
            "75%                             0.0                           0.0   \n",
            "max                             0.0                           0.0   \n",
            "\n",
            "        ERC20 uniq sent token name   ERC20 uniq rec token name  \n",
            "count                  9012.000000                 9012.000000  \n",
            "mean                      1.384931                    4.826676  \n",
            "std                       6.735121                   16.678607  \n",
            "min                       0.000000                    0.000000  \n",
            "25%                       0.000000                    0.000000  \n",
            "50%                       0.000000                    1.000000  \n",
            "75%                       0.000000                    2.000000  \n",
            "max                     213.000000                  737.000000  \n",
            "\n",
            "[8 rows x 48 columns]\n",
            "Missing Values:\n",
            "                                     Missing Count  Percentage\n",
            "Total ERC20 tnxs                               829    8.423941\n",
            "ERC20 total Ether received                     829    8.423941\n",
            "ERC20 total ether sent                         829    8.423941\n",
            "ERC20 total Ether sent contract                829    8.423941\n",
            "ERC20 uniq sent addr                           829    8.423941\n",
            "ERC20 uniq rec addr                            829    8.423941\n",
            "ERC20 uniq sent addr.1                         829    8.423941\n",
            "ERC20 uniq rec contract addr                   829    8.423941\n",
            "ERC20 avg time between sent tnx                829    8.423941\n",
            "ERC20 avg time between rec tnx                 829    8.423941\n",
            "ERC20 avg time between rec 2 tnx               829    8.423941\n",
            "ERC20 avg time between contract tnx            829    8.423941\n",
            "ERC20 min val rec                              829    8.423941\n",
            "ERC20 max val rec                              829    8.423941\n",
            "ERC20 avg val rec                              829    8.423941\n",
            "ERC20 min val sent                             829    8.423941\n",
            "ERC20 max val sent                             829    8.423941\n",
            "ERC20 avg val sent                             829    8.423941\n",
            "ERC20 min val sent contract                    829    8.423941\n",
            "ERC20 max val sent contract                    829    8.423941\n",
            "ERC20 avg val sent contract                    829    8.423941\n",
            "ERC20 uniq sent token name                     829    8.423941\n",
            "ERC20 uniq rec token name                      829    8.423941\n",
            "ERC20 most sent token type                    2697   27.405751\n",
            "ERC20_most_rec_token_type                      871    8.850727\n",
            "Class Distribution (FLAG):\n",
            "FLAG\n",
            "0    7662\n",
            "1    2179\n",
            "Name: count, dtype: int64\n",
            "Fraud Percentage: 22.14%\n",
            "Clean Percentage: 77.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA PREPROCESSING\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[fraud_col] if fraud_col else [], errors='ignore')\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(f\"Numeric Features ({len(numeric_cols)}): {numeric_cols[:5]}{'...' if len(numeric_cols) > 5 else ''}\")\n",
        "print(f\"Categorical Features ({len(categorical_cols)}): {categorical_cols}\")\n",
        "\n",
        "# Handle categorical features\n",
        "if categorical_cols:\n",
        "    print(\"Encoding categorical features...\")\n",
        "    le = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        X[col] = le.fit_transform(X[col].astype(str))\n",
        "    print(\"Categorical encoding complete!\")\n",
        "\n",
        "# Handle missing values (if any)\n",
        "if X.isnull().sum().sum() > 0:\n",
        "    print(\"Handling missing values...\")\n",
        "    X = X.fillna(X.median())\n",
        "    print(\"Missing values filled with median!\")\n",
        "\n",
        "# Remove any non-numeric columns that couldn't be processed\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "print(f\"Final feature matrix shape: {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxolR0eo_qSw",
        "outputId": "03995b1b-0965-4fb6-81b0-766bba54ce1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DATA PREPROCESSING\n",
            "================================================================================\n",
            "Numeric Features (47): ['Unnamed: 0', 'Index', 'Avg min between sent tnx', 'Avg min between received tnx', 'Time Diff between first and last (Mins)']...\n",
            "Categorical Features (3): ['Address', ' ERC20 most sent token type', ' ERC20_most_rec_token_type']\n",
            "Encoding categorical features...\n",
            "Categorical encoding complete!\n",
            "Handling missing values...\n",
            "Missing values filled with median!\n",
            "Final feature matrix shape: (9841, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VISUALISATION - FEATURE DISTRIBUTIONS\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GENERATING VISUALIZATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Plot distributions of key features\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Feature Distributions', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, col in enumerate(X.columns[:6]):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "    ax.hist(X[col], bins=50, edgecolor='black', alpha=0.7)\n",
        "    ax.set_title(f'{col}', fontweight='bold')\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: feature_distributions.png\")\n",
        "plt.close()\n",
        "\n",
        "# Correlation heatmap\n",
        "print(\"Generating correlation heatmap...\")\n",
        "plt.figure(figsize=(14, 12))\n",
        "correlation_matrix = X.corr()\n",
        "\n",
        "# For large datasets, show only top correlations\n",
        "if len(X.columns) > 20:\n",
        "    # Get top 20 features with highest variance\n",
        "    top_features = X.var().nlargest(20).index\n",
        "    correlation_matrix = X[top_features].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=0.5)\n",
        "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: correlation_heatmap.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gAGaabg_4j7",
        "outputId": "e9a2b97a-7373-4c3c-b01f-39491f04a67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "GENERATING VISUALIZATIONS\n",
            "================================================================================\n",
            "Saved: feature_distributions.png\n",
            "Generating correlation heatmap...\n",
            "Saved: correlation_heatmap.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN/TEST SPLIT\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TRAIN/TEST SPLIT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y if fraud_col else None\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
        "\n",
        "# Normalize features\n",
        "print(\"Normalizing features with StandardScaler...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Feature scaling complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF_SwPV0AJBJ",
        "outputId": "7d7fd5c2-4663-45e7-c5c7-d8d8352d0eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAIN/TEST SPLIT\n",
            "================================================================================\n",
            "Training set: 6,888 samples\n",
            "Test set: 2,953 samples\n",
            "Normalizing features with StandardScaler...\n",
            "Feature scaling complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL TRAINING - ISOLATION FOREST\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MODEL TRAINING - ISOLATION FOREST\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate contamination based on actual fraud rate\n",
        "if fraud_col:\n",
        "    contamination_rate = y_train.sum() / len(y_train)\n",
        "    contamination_rate = max(0.01, min(0.5, contamination_rate))  # Bound between 1% and 50%\n",
        "else:\n",
        "    contamination_rate = 0.1\n",
        "\n",
        "print(f\"Contamination rate: {contamination_rate:.4f}\")\n",
        "\n",
        "# Train Isolation Forest with parameter tuning\n",
        "print(\"Training Isolation Forest with hyperparameter tuning...\")\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_samples': [256, 512, 'auto'],\n",
        "    'contamination': [contamination_rate * 0.8, contamination_rate, contamination_rate * 1.2],\n",
        "    'max_features': [0.5, 0.75, 1.0]\n",
        "}\n",
        "\n",
        "best_f1 = 0\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "# Manual grid search (since IsolationForest doesn't support GridSearchCV directly)\n",
        "for n_est in param_grid['n_estimators']:\n",
        "    for max_samp in param_grid['max_samples']:\n",
        "        for contam in param_grid['contamination']:\n",
        "            for max_feat in param_grid['max_features']:\n",
        "                model = IsolationForest(\n",
        "                    n_estimators=n_est,\n",
        "                    max_samples=max_samp,\n",
        "                    contamination=contam,\n",
        "                    max_features=max_feat,\n",
        "                    random_state=42,\n",
        "                    n_jobs=-1\n",
        "                )\n",
        "\n",
        "                model.fit(X_train_scaled)\n",
        "                y_pred = model.predict(X_test_scaled)\n",
        "                y_pred = np.where(y_pred == -1, 1, 0)  # Convert to 0/1\n",
        "\n",
        "                if y_test.sum() > 0:  # Only calculate if there are positive samples\n",
        "                    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "                    if f1 > best_f1:\n",
        "                        best_f1 = f1\n",
        "                        best_params = {\n",
        "                            'n_estimators': n_est,\n",
        "                            'max_samples': max_samp,\n",
        "                            'contamination': contam,\n",
        "                            'max_features': max_feat\n",
        "                        }\n",
        "                        best_model = model\n",
        "\n",
        "if best_model is None:\n",
        "    # Fallback to default model\n",
        "    best_model = IsolationForest(\n",
        "        n_estimators=200,\n",
        "        contamination=contamination_rate,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    best_model.fit(X_train_scaled)\n",
        "    best_params = {'n_estimators': 200, 'contamination': contamination_rate}\n",
        "\n",
        "print(f\"Best parameters found:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"   {param}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x4uMtqxASZN",
        "outputId": "ff37e975-9c3e-4bbe-b2bb-00d1fa8ae42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "MODEL TRAINING - ISOLATION FOREST\n",
            "================================================================================\n",
            "Contamination rate: 0.2214\n",
            "Training Isolation Forest with hyperparameter tuning...\n",
            "Best parameters found:\n",
            "   n_estimators: 100\n",
            "   max_samples: 512\n",
            "   contamination: 0.2656794425087108\n",
            "   max_features: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTIONS AND SCORING\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PREDICTIONS AND SCORING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get anomaly scores and predictions\n",
        "anomaly_scores = best_model.score_samples(X_test_scaled)\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "y_pred_binary = np.where(y_pred == -1, 1, 0)  # -1 = anomaly (fraud), 1 = normal\n",
        "\n",
        "# Create scaled rating (1-10 scale)\n",
        "# Anomaly scores are typically in range [-0.5, 0.5] but can vary\n",
        "# Lower score = more anomalous = higher fraud risk = lower rating\n",
        "score_min = anomaly_scores.min()\n",
        "score_max = anomaly_scores.max()\n",
        "\n",
        "# Normalize to [0, 1] then scale to [1, 10]\n",
        "normalized_scores = (anomaly_scores - score_min) / (score_max - score_min)\n",
        "scaled_ratings = normalized_scores * 9 + 1  # Scale to 1-10\n",
        "scaled_ratings = np.round(scaled_ratings, 1)\n",
        "\n",
        "print(f\"Anomaly Score Statistics:\")\n",
        "print(f\"   Min: {anomaly_scores.min():.4f}\")\n",
        "print(f\"   Max: {anomaly_scores.max():.4f}\")\n",
        "print(f\"   Mean: {anomaly_scores.mean():.4f}\")\n",
        "print(f\"   Std: {anomaly_scores.std():.4f}\")\n",
        "\n",
        "print(f\"Scaled Rating Statistics (1-10):\")\n",
        "print(f\"   Min: {scaled_ratings.min():.1f}\")\n",
        "print(f\"   Max: {scaled_ratings.max():.1f}\")\n",
        "print(f\"   Mean: {scaled_ratings.mean():.1f}\")\n",
        "print(f\"   Std: {scaled_ratings.std():.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KFD9zHsAiPa",
        "outputId": "794c4725-3015-45fb-e561-a0b6e7fb07eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PREDICTIONS AND SCORING\n",
            "================================================================================\n",
            "Anomaly Score Statistics:\n",
            "   Min: -0.7489\n",
            "   Max: -0.3150\n",
            "   Mean: -0.3476\n",
            "   Std: 0.0449\n",
            "Scaled Rating Statistics (1-10):\n",
            "   Min: 1.0\n",
            "   Max: 10.0\n",
            "   Mean: 9.3\n",
            "   Std: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL EVALUATION\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if y_test.sum() > 0:  # Only evaluate if there are positive samples\n",
        "    precision = precision_score(y_test, y_pred_binary, zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred_binary, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred_binary, zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_test, -anomaly_scores)  # Negative because lower = more anomalous\n",
        "\n",
        "    print(f\"Performance Metrics:\")\n",
        "    print(f\"   Precision: {precision:.4f}\")\n",
        "    print(f\"   Recall:    {recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {f1:.4f}\")\n",
        "    print(f\"   ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, y_pred_binary)\n",
        "    print(cm)\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_binary,\n",
        "                                target_names=['Clean', 'Fraud'],\n",
        "                                zero_division=0))\n",
        "else:\n",
        "    print(\"No fraud samples in test set - skipping performance metrics\")\n",
        "    roc_auc = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YC3qsMUAs_O",
        "outputId": "5945d9ad-92b1-4eb3-d23a-221a69085070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "MODEL EVALUATION\n",
            "================================================================================\n",
            "Performance Metrics:\n",
            "   Precision: 0.1407\n",
            "   Recall:    0.1682\n",
            "   F1-Score:  0.1532\n",
            "   ROC-AUC:   0.4743\n",
            "Confusion Matrix:\n",
            "[[1627  672]\n",
            " [ 544  110]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Clean       0.75      0.71      0.73      2299\n",
            "       Fraud       0.14      0.17      0.15       654\n",
            "\n",
            "    accuracy                           0.59      2953\n",
            "   macro avg       0.45      0.44      0.44      2953\n",
            "weighted avg       0.61      0.59      0.60      2953\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VISUALIZATIONS - RESULTS\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GENERATING RESULT VISUALIZATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Anomaly score distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "axes[0].hist(anomaly_scores[y_test == 0], bins=50, alpha=0.7, label='Clean', color='blue')\n",
        "axes[0].hist(anomaly_scores[y_test == 1], bins=50, alpha=0.7, label='Fraud', color='red')\n",
        "axes[0].set_xlabel('Anomaly Score', fontweight='bold')\n",
        "axes[0].set_ylabel('Frequency', fontweight='bold')\n",
        "axes[0].set_title('Anomaly Score Distribution', fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Scaled rating distribution\n",
        "axes[1].hist(scaled_ratings[y_test == 0], bins=50, alpha=0.7, label='Clean', color='blue')\n",
        "axes[1].hist(scaled_ratings[y_test == 1], bins=50, alpha=0.7, label='Fraud', color='red')\n",
        "axes[1].set_xlabel('Scaled Rating (1-10)', fontweight='bold')\n",
        "axes[1].set_ylabel('Frequency', fontweight='bold')\n",
        "axes[1].set_title('Scaled Rating Distribution', fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('anomaly_score_distribution.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: anomaly_score_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "# ROC Curve\n",
        "if roc_auc is not None:\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, -anomaly_scores)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontweight='bold', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontweight='bold', fontsize=12)\n",
        "    plt.title('ROC Curve - Isolation Forest', fontweight='bold', fontsize=14)\n",
        "    plt.legend(loc=\"lower right\", fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: roc_curve.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA5MXgzyA2kW",
        "outputId": "a4d9bc65-02a7-465d-da03-afd40f35aa50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "GENERATING RESULT VISUALIZATIONS\n",
            "================================================================================\n",
            "Saved: anomaly_score_distribution.png\n",
            "Saved: roc_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OUTPUT RESULTS\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL RESULTS OUTPUT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Transaction_Index': X_test.index,\n",
        "    'Anomaly_Score': anomaly_scores,\n",
        "    'Prediction': ['Fraud' if p == 1 else 'Clean' for p in y_pred_binary],\n",
        "    'Scaled_Rating_1_10': scaled_ratings,\n",
        "    'Actual_Label': ['Fraud' if y == 1 else 'Clean' for y in y_test]\n",
        "})\n",
        "\n",
        "# Sort by fraud risk (lowest rating = highest risk)\n",
        "results_df = results_df.sort_values('Scaled_Rating_1_10')\n",
        "\n",
        "print(\"Sample Results (Top 10 Highest Risk):\")\n",
        "print(results_df.head(10).to_string(index=False))\n",
        "\n",
        "print(\"Sample Results (Top 10 Lowest Risk):\")\n",
        "print(results_df.tail(10).to_string(index=False))\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('fraud_detection_results.csv', index=False)\n",
        "print(\"Full results saved to: fraud_detection_results.csv\")\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total transactions analyzed: {len(results_df):,}\")\n",
        "print(f\"Flagged as fraud: {(y_pred_binary == 1).sum():,} ({(y_pred_binary == 1).sum() / len(y_pred_binary) * 100:.2f}%)\")\n",
        "print(f\"Flagged as clean: {(y_pred_binary == 0).sum():,} ({(y_pred_binary == 0).sum() / len(y_pred_binary) * 100:.2f}%)\")\n",
        "\n",
        "if y_test.sum() > 0:\n",
        "    print(f\"Model Performance Summary:\")\n",
        "    print(f\"   • Precision: {precision:.2%} (of flagged frauds, how many were correct)\")\n",
        "    print(f\"   • Recall: {recall:.2%} (of actual frauds, how many were caught)\")\n",
        "    print(f\"   • F1-Score: {f1:.4f} (harmonic mean of precision and recall)\")\n",
        "    print(f\"   • ROC-AUC: {roc_auc:.4f} (overall discriminative ability)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FRAUD DETECTION ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Generated Files:\")\n",
        "print(\"   • feature_distributions.png\")\n",
        "print(\"   • correlation_heatmap.png\")\n",
        "print(\"   • anomaly_score_distribution.png\")\n",
        "print(\"   • roc_curve.png\")\n",
        "print(\"   • fraud_detection_results.csv\")\n",
        "print(\"\\n\" + \"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiGQIeXbA-rP",
        "outputId": "f615101c-688a-434d-88d9-2d5433da967c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL RESULTS OUTPUT\n",
            "================================================================================\n",
            "Sample Results (Top 10 Highest Risk):\n",
            " Transaction_Index  Anomaly_Score Prediction  Scaled_Rating_1_10 Actual_Label\n",
            "               454      -0.748923      Fraud                 1.0        Clean\n",
            "                54      -0.745756      Fraud                 1.1        Clean\n",
            "               914      -0.713719      Fraud                 1.7        Clean\n",
            "               525      -0.706238      Fraud                 1.9        Clean\n",
            "               145      -0.700745      Fraud                 2.0        Clean\n",
            "              4702      -0.675440      Fraud                 2.5        Clean\n",
            "               878      -0.670026      Fraud                 2.6        Clean\n",
            "              3140      -0.650598      Fraud                 3.0        Clean\n",
            "               158      -0.646473      Fraud                 3.1        Clean\n",
            "              2262      -0.649262      Fraud                 3.1        Clean\n",
            "Sample Results (Top 10 Lowest Risk):\n",
            " Transaction_Index  Anomaly_Score Prediction  Scaled_Rating_1_10 Actual_Label\n",
            "              5222      -0.317069      Clean                10.0        Clean\n",
            "              5688      -0.315949      Clean                10.0        Clean\n",
            "              3730      -0.316480      Clean                10.0        Clean\n",
            "              6106      -0.316270      Clean                10.0        Clean\n",
            "              5083      -0.315481      Clean                10.0        Clean\n",
            "              3969      -0.315623      Clean                10.0        Clean\n",
            "              8769      -0.317249      Clean                10.0        Fraud\n",
            "              5390      -0.315794      Clean                10.0        Clean\n",
            "              5145      -0.316058      Clean                10.0        Clean\n",
            "              3972      -0.315623      Clean                10.0        Clean\n",
            "Full results saved to: fraud_detection_results.csv\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "Total transactions analyzed: 2,953\n",
            "Flagged as fraud: 782 (26.48%)\n",
            "Flagged as clean: 2,171 (73.52%)\n",
            "Model Performance Summary:\n",
            "   • Precision: 14.07% (of flagged frauds, how many were correct)\n",
            "   • Recall: 16.82% (of actual frauds, how many were caught)\n",
            "   • F1-Score: 0.1532 (harmonic mean of precision and recall)\n",
            "   • ROC-AUC: 0.4743 (overall discriminative ability)\n",
            "\n",
            "================================================================================\n",
            "✅ FRAUD DETECTION ANALYSIS COMPLETE!\n",
            "================================================================================\n",
            "Generated Files:\n",
            "   • feature_distributions.png\n",
            "   • correlation_heatmap.png\n",
            "   • anomaly_score_distribution.png\n",
            "   • roc_curve.png\n",
            "   • fraud_detection_results.csv\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}