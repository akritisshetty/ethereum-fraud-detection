{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install torch torch-geometric pandas numpy scikit-learn matplotlib seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v717VhbRWTY7",
        "outputId": "8994ddd4-95bc-4956-8951-b213c0395487"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
        "from torch_geometric.utils import from_networkx\n",
        "import networkx as nx\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "S9aKwrGXWWF2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 1: Load and Explore Data\n",
        "# ============================================================================\n",
        "\n",
        "df = pd.read_csv('transactions.csv')\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: Data Preprocessing and Graph Construction\n",
        "# ============================================================================\n",
        "\n",
        "def preprocess_data(df):\n",
        "\n",
        "    print(\"DATA PREPROCESSING\")\n",
        "\n",
        "    # Display basic info\n",
        "    print(f\"\\nDataset shape: {df.shape}\")\n",
        "    print(f\"Columns: {df.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Check for fraud distribution\n",
        "    if 'is_fraud' in df.columns:\n",
        "        fraud_dist = df['is_fraud'].value_counts()\n",
        "        print(f\"\\nFraud Distribution:\")\n",
        "        print(fraud_dist)\n",
        "        print(f\"Fraud Rate: {fraud_dist[1]/len(df)*100:.2f}%\")\n",
        "\n",
        "    # Handle missing values\n",
        "    df = df.dropna(subset=['from_address', 'to_address'])\n",
        "\n",
        "    return df\n",
        "\n",
        "def build_graph(df):\n",
        "    \"\"\"\n",
        "    Build transaction graph from dataframe\n",
        "    Nodes: Addresses\n",
        "    Edges: Transactions\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"GRAPH CONSTRUCTION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create unique node mapping\n",
        "    unique_addresses = pd.concat([df['from_address'], df['to_address']]).unique()\n",
        "    node_to_idx = {addr: idx for idx, addr in enumerate(unique_addresses)}\n",
        "    idx_to_node = {idx: addr for addr, idx in node_to_idx.items()}\n",
        "\n",
        "    print(f\"\\nNumber of unique addresses (nodes): {len(unique_addresses)}\")\n",
        "    print(f\"Number of transactions (edges): {len(df)}\")\n",
        "\n",
        "    # Create edge index\n",
        "    edge_index = []\n",
        "    edge_attr = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        from_idx = node_to_idx[row['from_address']]\n",
        "        to_idx = node_to_idx[row['to_address']]\n",
        "\n",
        "        edge_index.append([from_idx, to_idx])\n",
        "\n",
        "        # Edge features: amount, gas_used, etc.\n",
        "        edge_features = []\n",
        "        if 'amount' in df.columns:\n",
        "            edge_features.append(float(row['amount']))\n",
        "        if 'gas_used' in df.columns:\n",
        "            edge_features.append(float(row['gas_used']))\n",
        "        if 'gas_price' in df.columns:\n",
        "            edge_features.append(float(row['gas_price']))\n",
        "\n",
        "        edge_attr.append(edge_features)\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "\n",
        "    # Create node features\n",
        "    node_features = create_node_features(df, node_to_idx)\n",
        "\n",
        "    # Create node labels (fraud or not)\n",
        "    node_labels = create_node_labels(df, node_to_idx)\n",
        "\n",
        "    return edge_index, edge_attr, node_features, node_labels, node_to_idx, idx_to_node\n",
        "\n",
        "def create_node_features(df, node_to_idx):\n",
        "    \"\"\"\n",
        "    Create node features based on transaction patterns\n",
        "    \"\"\"\n",
        "    print(\"\\nCreating node features...\")\n",
        "\n",
        "    num_nodes = len(node_to_idx)\n",
        "    features = []\n",
        "\n",
        "    for addr, idx in node_to_idx.items():\n",
        "        # Outgoing transactions\n",
        "        out_txs = df[df['from_address'] == addr]\n",
        "        in_txs = df[df['to_address'] == addr]\n",
        "\n",
        "        feature_vector = [\n",
        "            len(out_txs),  # Number of outgoing transactions\n",
        "            len(in_txs),   # Number of incoming transactions\n",
        "            out_txs['amount'].sum() if 'amount' in df.columns and len(out_txs) > 0 else 0,\n",
        "            in_txs['amount'].sum() if 'amount' in df.columns and len(in_txs) > 0 else 0,\n",
        "            out_txs['amount'].mean() if 'amount' in df.columns and len(out_txs) > 0 else 0,\n",
        "            in_txs['amount'].mean() if 'amount' in df.columns and len(in_txs) > 0 else 0,\n",
        "            out_txs['gas_used'].mean() if 'gas_used' in df.columns and len(out_txs) > 0 else 0,\n",
        "            in_txs['gas_used'].mean() if 'gas_used' in df.columns and len(in_txs) > 0 else 0,\n",
        "        ]\n",
        "        features.append(feature_vector)\n",
        "\n",
        "    features = np.array(features)\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features)\n",
        "\n",
        "    print(f\"Node feature shape: {features.shape}\")\n",
        "\n",
        "    return torch.tensor(features, dtype=torch.float)\n",
        "\n",
        "def create_node_labels(df, node_to_idx):\n",
        "    \"\"\"\n",
        "    Create node labels (1 if involved in fraud, 0 otherwise)\n",
        "    \"\"\"\n",
        "    print(\"Creating node labels...\")\n",
        "\n",
        "    labels = np.zeros(len(node_to_idx))\n",
        "\n",
        "    if 'is_fraud' in df.columns:\n",
        "        fraud_txs = df[df['is_fraud'] == 1]\n",
        "\n",
        "        for _, row in fraud_txs.iterrows():\n",
        "            from_idx = node_to_idx[row['from_address']]\n",
        "            to_idx = node_to_idx[row['to_address']]\n",
        "            labels[from_idx] = 1\n",
        "            labels[to_idx] = 1\n",
        "\n",
        "        print(f\"Fraudulent nodes: {labels.sum()}/{len(labels)} ({labels.sum()/len(labels)*100:.2f}%)\")\n",
        "\n",
        "    return torch.tensor(labels, dtype=torch.long)"
      ],
      "metadata": {
        "id": "iirgntlSXDCZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: GNN Model Definition\n",
        "# ============================================================================\n",
        "\n",
        "class GCN_FraudDetector(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Convolutional Network for Fraud Detection\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, hidden_channels):\n",
        "        super(GCN_FraudDetector, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels // 2)\n",
        "        self.linear = torch.nn.Linear(hidden_channels // 2, 2)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.linear(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GraphSAGE_FraudDetector(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    GraphSAGE for Fraud Detection\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, hidden_channels):\n",
        "        super(GraphSAGE_FraudDetector, self).__init__()\n",
        "        self.conv1 = SAGEConv(num_features, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels // 2)\n",
        "        self.linear = torch.nn.Linear(hidden_channels // 2, 2)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.linear(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GAT_FraudDetector(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Attention Network for Fraud Detection\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, hidden_channels):\n",
        "        super(GAT_FraudDetector, self).__init__()\n",
        "        self.conv1 = GATConv(num_features, hidden_channels, heads=8, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_channels * 8, hidden_channels, heads=1, concat=False, dropout=0.6)\n",
        "        self.linear = torch.nn.Linear(hidden_channels, 2)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.linear(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "nNc-0JmYXG9O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 4: Training and Evaluation\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, data, train_mask, optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[train_mask], data.y[train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate_model(model, data, mask):\n",
        "    \"\"\"\n",
        "    Evaluate the model\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct = (pred[mask] == data.y[mask]).sum()\n",
        "        acc = int(correct) / int(mask.sum())\n",
        "    return acc, pred\n",
        "\n",
        "def train_and_evaluate(model_class, model_name, data, epochs=200, lr=0.01, hidden_channels=64):\n",
        "    \"\"\"\n",
        "    Complete training and evaluation pipeline\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"TRAINING {model_name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Initialize model\n",
        "    model = model_class(data.num_features, hidden_channels)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "\n",
        "    # Training loop\n",
        "    train_losses = []\n",
        "    val_accs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss = train_model(model, data, data.train_mask, optimizer, criterion)\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if epoch % 20 == 0:\n",
        "            train_acc, _ = evaluate_model(model, data, data.train_mask)\n",
        "            val_acc, _ = evaluate_model(model, data, data.val_mask)\n",
        "            val_accs.append(val_acc)\n",
        "            print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "    # Final evaluation\n",
        "    test_acc, test_pred = evaluate_model(model, data, data.test_mask)\n",
        "    print(f'\\n{model_name} Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "    # Detailed metrics\n",
        "    y_true = data.y[data.test_mask].cpu().numpy()\n",
        "    y_pred = test_pred[data.test_mask].cpu().numpy()\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=['Normal', 'Fraud']))\n",
        "\n",
        "    return model, train_losses, val_accs, y_true, y_pred"
      ],
      "metadata": {
        "id": "SaReaMXyXLYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 5: Visualization\n",
        "# ============================================================================\n",
        "\n",
        "def plot_results(train_losses, model_name):\n",
        "    \"\"\"\n",
        "    Plot training curves\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses)\n",
        "    plt.title(f'{model_name} - Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "def compare_models(results):\n",
        "    \"\"\"\n",
        "    Compare multiple models\n",
        "    \"\"\"\n",
        "    models = list(results.keys())\n",
        "    accuracies = [results[m]['test_acc'] for m in models]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(models, accuracies, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "    plt.title('Model Comparison - Test Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim([0, 1])\n",
        "    for i, v in enumerate(accuracies):\n",
        "        plt.text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HP_z0NZHXPnN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uZWGSUYXVipH",
        "outputId": "2a79cec0-0829-4393-a854-9c3fc4d66693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN-BASED FRAUD DETECTION SYSTEM\n",
            "DATA PREPROCESSING\n",
            "\n",
            "Dataset shape: (485576, 9)\n",
            "Columns: ['tx_hash', 'from_wallet', 'to_wallet', 'token', 'amount', 'timestamp', 'gas_fee_usd', 'platform', 'tx_type']\n",
            "\n",
            "First few rows:\n",
            "                                             tx_hash  \\\n",
            "0  0xc40e0b25086f94703e134ffc6cab543321f7610c0302...   \n",
            "1  0x2e32672b7ccb2c55db06c91ca17122dea7c1c6f7f848...   \n",
            "2  0x3d2cde2b23d28e641a6d5f2e013f0507213c00ca34ef...   \n",
            "3  0x21c59e7a4f0fc4b1d7b5675e6c8416d0ac0f6b85ed8b...   \n",
            "4  0x37a1cc6eab2bf725091ea66a44625e34c76eb005f5dc...   \n",
            "\n",
            "                                  from_wallet  \\\n",
            "0  0xd99d937bfcbe7f83bc761bf0fe3316fdfde27202   \n",
            "1  0x20ad73be3c5ec493f2033ff9bc7d60fb5d4cdb95   \n",
            "2  0x52e3343a7b26c07e6dd7f3c16b3a79cf496123b7   \n",
            "3  0x93bc0e6b2790e4ddd7c3c8779e218ed2b3ecee40   \n",
            "4  0x4ebcc8d240d2e3be0bc39c5485ea707fec7007d0   \n",
            "\n",
            "                                    to_wallet token     amount  \\\n",
            "0  0x3d3d6ad4dc669c598c31454a3f73410da25922fe   DAI   4.466987   \n",
            "1  0x3d6f42ea21ae34d48eec8a53991b4020047d491c   UNI   2.367266   \n",
            "2  0x92cf01d92fa41776ad2493336066dc55d6e69a96   UNI   5.194958   \n",
            "3  0xca80b638cb4ea61cf1ff18e788731ae99e214372  SHIB  12.466311   \n",
            "4  0xbcee8de49ec86476ab995cff4c8d06f15ba95062  USDC   2.150815   \n",
            "\n",
            "             timestamp  gas_fee_usd   platform   tx_type  \n",
            "0  2022-03-13 21:56:21       0.7288   Compound  transfer  \n",
            "1  2022-01-03 14:56:17       0.5694  Sushiswap      lend  \n",
            "2  2022-01-08 21:43:49       2.5620    Uniswap     stake  \n",
            "3  2022-07-22 13:45:23       3.9805      Curve      lend  \n",
            "4  2022-08-26 12:15:31       0.3482   Compound  transfer  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "['from_address', 'to_address']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-337010997.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Build graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2359712876.py\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Handle missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'from_address'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to_address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ['from_address', 'to_address']"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "print(\"GNN-BASED FRAUD DETECTION SYSTEM\")\n",
        "\n",
        "# STEP 0: First, explore your data to understand its structure\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv('transactions.csv')\n",
        "\n",
        "# Preprocess\n",
        "df = preprocess_data(df)\n",
        "\n",
        "# Build graph\n",
        "edge_index, edge_attr, node_features, node_labels, node_to_idx, idx_to_node = build_graph(df)\n",
        "\n",
        "# Create PyTorch Geometric Data object\n",
        "data = Data(x=node_features, edge_index=edge_index, y=node_labels)\n",
        "\n",
        "# Create train/val/test masks\n",
        "num_nodes = len(node_labels)\n",
        "indices = np.arange(num_nodes)\n",
        "train_idx, temp_idx = train_test_split(indices, train_size=0.7, stratify=node_labels.numpy())\n",
        "val_idx, test_idx = train_test_split(temp_idx, train_size=0.5, stratify=node_labels[temp_idx].numpy())\n",
        "\n",
        "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "data.train_mask[train_idx] = True\n",
        "data.val_mask[val_idx] = True\n",
        "data.test_mask[test_idx] = True\n",
        "\n",
        "print(f\"\\nData splits - Train: {data.train_mask.sum()}, Val: {data.val_mask.sum()}, Test: {data.test_mask.sum()}\")\n",
        "\n",
        "# Train multiple models\n",
        "results = {}\n",
        "\n",
        "# GCN\n",
        "model_gcn, losses_gcn, _, y_true_gcn, y_pred_gcn = train_and_evaluate(\n",
        "    GCN_FraudDetector, \"GCN\", data, epochs=200\n",
        ")\n",
        "results['GCN'] = {'test_acc': (y_true_gcn == y_pred_gcn).mean()}\n",
        "plot_results(losses_gcn, \"GCN\")\n",
        "plot_confusion_matrix(y_true_gcn, y_pred_gcn, \"GCN\")\n",
        "\n",
        "# GraphSAGE\n",
        "model_sage, losses_sage, _, y_true_sage, y_pred_sage = train_and_evaluate(\n",
        "    GraphSAGE_FraudDetector, \"GraphSAGE\", data, epochs=200\n",
        ")\n",
        "results['GraphSAGE'] = {'test_acc': (y_true_sage == y_pred_sage).mean()}\n",
        "plot_results(losses_sage, \"GraphSAGE\")\n",
        "plot_confusion_matrix(y_true_sage, y_pred_sage, \"GraphSAGE\")\n",
        "\n",
        "# GAT\n",
        "model_gat, losses_gat, _, y_true_gat, y_pred_gat = train_and_evaluate(\n",
        "    GAT_FraudDetector, \"GAT\", data, epochs=200\n",
        ")\n",
        "results['GAT'] = {'test_acc': (y_true_gat == y_pred_gat).mean()}\n",
        "plot_results(losses_gat, \"GAT\")\n",
        "plot_confusion_matrix(y_true_gat, y_pred_gat, \"GAT\")\n",
        "\n",
        "# Compare all models\n",
        "compare_models(results)\n",
        "\n",
        "# Save best model\n",
        "best_model_name = max(results, key=lambda x: results[x]['test_acc'])\n",
        "print(f\"\\nBest Model: {best_model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJpvbYnAYRe6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}