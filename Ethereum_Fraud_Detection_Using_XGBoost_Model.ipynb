{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0iNJjQ-SRRJ"
      },
      "outputs": [],
      "source": [
        "# IMPORTING LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, accuracy_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix,\n",
        "    classification_report, precision_recall_curve, auc\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxZ9ImIhSRpE"
      },
      "outputs": [],
      "source": [
        "# Set style for better visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar6v72uaHRsR",
        "outputId": "bf58b978-6c6a-48b2-9e6c-5d3c68f18707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ETHEREUM FRAUD DETECTION - XGBOOST\n",
            "Dataset Shape: (9841, 51)\n",
            "   Rows: 9,841 | Columns: 51\n"
          ]
        }
      ],
      "source": [
        "# LOADING DATASET\n",
        "print(\"ETHEREUM FRAUD DETECTION - XGBOOST\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/transaction_dataset.csv\")\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"   Rows: {df.shape[0]:,} | Columns: {df.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7iQ8pJ_-E0G",
        "outputId": "bebf4e2a-72ec-4c97-810c-d9c69a51426c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXPLORATORY DATA ANALYSIS\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9841 entries, 0 to 9840\n",
            "Data columns (total 51 columns):\n",
            " #   Column                                                Non-Null Count  Dtype  \n",
            "---  ------                                                --------------  -----  \n",
            " 0   Unnamed: 0                                            9841 non-null   int64  \n",
            " 1   Index                                                 9841 non-null   int64  \n",
            " 2   Address                                               9841 non-null   object \n",
            " 3   FLAG                                                  9841 non-null   int64  \n",
            " 4   Avg min between sent tnx                              9841 non-null   float64\n",
            " 5   Avg min between received tnx                          9841 non-null   float64\n",
            " 6   Time Diff between first and last (Mins)               9841 non-null   float64\n",
            " 7   Sent tnx                                              9841 non-null   int64  \n",
            " 8   Received Tnx                                          9841 non-null   int64  \n",
            " 9   Number of Created Contracts                           9841 non-null   int64  \n",
            " 10  Unique Received From Addresses                        9841 non-null   int64  \n",
            " 11  Unique Sent To Addresses                              9841 non-null   int64  \n",
            " 12  min value received                                    9841 non-null   float64\n",
            " 13  max value received                                    9841 non-null   float64\n",
            " 14  avg val received                                      9841 non-null   float64\n",
            " 15  min val sent                                          9841 non-null   float64\n",
            " 16  max val sent                                          9841 non-null   float64\n",
            " 17  avg val sent                                          9841 non-null   float64\n",
            " 18  min value sent to contract                            9841 non-null   float64\n",
            " 19  max val sent to contract                              9841 non-null   float64\n",
            " 20  avg value sent to contract                            9841 non-null   float64\n",
            " 21  total transactions (including tnx to create contract  9841 non-null   int64  \n",
            " 22  total Ether sent                                      9841 non-null   float64\n",
            " 23  total ether received                                  9841 non-null   float64\n",
            " 24  total ether sent contracts                            9841 non-null   float64\n",
            " 25  total ether balance                                   9841 non-null   float64\n",
            " 26   Total ERC20 tnxs                                     9012 non-null   float64\n",
            " 27   ERC20 total Ether received                           9012 non-null   float64\n",
            " 28   ERC20 total ether sent                               9012 non-null   float64\n",
            " 29   ERC20 total Ether sent contract                      9012 non-null   float64\n",
            " 30   ERC20 uniq sent addr                                 9012 non-null   float64\n",
            " 31   ERC20 uniq rec addr                                  9012 non-null   float64\n",
            " 32   ERC20 uniq sent addr.1                               9012 non-null   float64\n",
            " 33   ERC20 uniq rec contract addr                         9012 non-null   float64\n",
            " 34   ERC20 avg time between sent tnx                      9012 non-null   float64\n",
            " 35   ERC20 avg time between rec tnx                       9012 non-null   float64\n",
            " 36   ERC20 avg time between rec 2 tnx                     9012 non-null   float64\n",
            " 37   ERC20 avg time between contract tnx                  9012 non-null   float64\n",
            " 38   ERC20 min val rec                                    9012 non-null   float64\n",
            " 39   ERC20 max val rec                                    9012 non-null   float64\n",
            " 40   ERC20 avg val rec                                    9012 non-null   float64\n",
            " 41   ERC20 min val sent                                   9012 non-null   float64\n",
            " 42   ERC20 max val sent                                   9012 non-null   float64\n",
            " 43   ERC20 avg val sent                                   9012 non-null   float64\n",
            " 44   ERC20 min val sent contract                          9012 non-null   float64\n",
            " 45   ERC20 max val sent contract                          9012 non-null   float64\n",
            " 46   ERC20 avg val sent contract                          9012 non-null   float64\n",
            " 47   ERC20 uniq sent token name                           9012 non-null   float64\n",
            " 48   ERC20 uniq rec token name                            9012 non-null   float64\n",
            " 49   ERC20 most sent token type                           7144 non-null   object \n",
            " 50   ERC20_most_rec_token_type                            8970 non-null   object \n",
            "dtypes: float64(39), int64(9), object(3)\n",
            "memory usage: 3.8+ MB\n",
            "None\n",
            "\n",
            "First Few Rows:\n",
            "   Unnamed: 0  Index                                     Address  FLAG  \\\n",
            "0           0      1  0x00009277775ac7d0d59eaad8fee3d10ac6c805e8     0   \n",
            "1           1      2  0x0002b44ddb1476db43c868bd494422ee4c136fed     0   \n",
            "2           2      3  0x0002bda54cb772d040f779e88eb453cac0daa244     0   \n",
            "3           3      4  0x00038e6ba2fd5c09aedb96697c8d7b8fa6632e5e     0   \n",
            "4           4      5  0x00062d1dd1afb6fb02540ddad9cdebfe568e0d89     0   \n",
            "\n",
            "   Avg min between sent tnx  Avg min between received tnx  \\\n",
            "0                    844.26                       1093.71   \n",
            "1                  12709.07                       2958.44   \n",
            "2                 246194.54                       2434.02   \n",
            "3                  10219.60                      15785.09   \n",
            "4                     36.61                      10707.77   \n",
            "\n",
            "   Time Diff between first and last (Mins)  Sent tnx  Received Tnx  \\\n",
            "0                                704785.63       721            89   \n",
            "1                               1218216.73        94             8   \n",
            "2                                516729.30         2            10   \n",
            "3                                397555.90        25             9   \n",
            "4                                382472.42      4598            20   \n",
            "\n",
            "   Number of Created Contracts  ...   ERC20 min val sent   ERC20 max val sent  \\\n",
            "0                            0  ...             0.000000         1.683100e+07   \n",
            "1                            0  ...             2.260809         2.260809e+00   \n",
            "2                            0  ...             0.000000         0.000000e+00   \n",
            "3                            0  ...           100.000000         9.029231e+03   \n",
            "4                            1  ...             0.000000         4.500000e+04   \n",
            "\n",
            "    ERC20 avg val sent   ERC20 min val sent contract  \\\n",
            "0        271779.920000                           0.0   \n",
            "1             2.260809                           0.0   \n",
            "2             0.000000                           0.0   \n",
            "3          3804.076893                           0.0   \n",
            "4         13726.659220                           0.0   \n",
            "\n",
            "    ERC20 max val sent contract   ERC20 avg val sent contract  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "3                           0.0                           0.0   \n",
            "4                           0.0                           0.0   \n",
            "\n",
            "    ERC20 uniq sent token name   ERC20 uniq rec token name  \\\n",
            "0                         39.0                        57.0   \n",
            "1                          1.0                         7.0   \n",
            "2                          0.0                         8.0   \n",
            "3                          1.0                        11.0   \n",
            "4                          6.0                        27.0   \n",
            "\n",
            "    ERC20 most sent token type   ERC20_most_rec_token_type  \n",
            "0                    Cofoundit                   Numeraire  \n",
            "1               Livepeer Token              Livepeer Token  \n",
            "2                          NaN                       XENON  \n",
            "3                       Raiden                       XENON  \n",
            "4                StatusNetwork                         EOS  \n",
            "\n",
            "[5 rows x 51 columns]\n",
            "\n",
            "Statistical Summary:\n",
            "        Unnamed: 0        Index         FLAG  Avg min between sent tnx  \\\n",
            "count  9841.000000  9841.000000  9841.000000               9841.000000   \n",
            "mean   4920.000000  1815.049893     0.221421               5086.878721   \n",
            "std    2840.996333  1222.621830     0.415224              21486.549974   \n",
            "min       0.000000     1.000000     0.000000                  0.000000   \n",
            "25%    2460.000000   821.000000     0.000000                  0.000000   \n",
            "50%    4920.000000  1641.000000     0.000000                 17.340000   \n",
            "75%    7380.000000  2601.000000     0.000000                565.470000   \n",
            "max    9840.000000  4729.000000     1.000000             430287.670000   \n",
            "\n",
            "       Avg min between received tnx  Time Diff between first and last (Mins)  \\\n",
            "count                   9841.000000                             9.841000e+03   \n",
            "mean                    8004.851184                             2.183333e+05   \n",
            "std                    23081.714801                             3.229379e+05   \n",
            "min                        0.000000                             0.000000e+00   \n",
            "25%                        0.000000                             3.169300e+02   \n",
            "50%                      509.770000                             4.663703e+04   \n",
            "75%                     5480.390000                             3.040710e+05   \n",
            "max                   482175.490000                             1.954861e+06   \n",
            "\n",
            "           Sent tnx  Received Tnx  Number of Created Contracts  \\\n",
            "count   9841.000000   9841.000000                  9841.000000   \n",
            "mean     115.931714    163.700945                     3.729702   \n",
            "std      757.226361    940.836550                   141.445583   \n",
            "min        0.000000      0.000000                     0.000000   \n",
            "25%        1.000000      1.000000                     0.000000   \n",
            "50%        3.000000      4.000000                     0.000000   \n",
            "75%       11.000000     27.000000                     0.000000   \n",
            "max    10000.000000  10000.000000                  9995.000000   \n",
            "\n",
            "       Unique Received From Addresses  ...   ERC20 max val rec  \\\n",
            "count                     9841.000000  ...        9.012000e+03   \n",
            "mean                        30.360939  ...        1.252524e+08   \n",
            "std                        298.621112  ...        1.053741e+10   \n",
            "min                          0.000000  ...        0.000000e+00   \n",
            "25%                          1.000000  ...        0.000000e+00   \n",
            "50%                          2.000000  ...        0.000000e+00   \n",
            "75%                          5.000000  ...        9.900000e+01   \n",
            "max                       9999.000000  ...        1.000000e+12   \n",
            "\n",
            "        ERC20 avg val rec   ERC20 min val sent   ERC20 max val sent  \\\n",
            "count        9.012000e+03         9.012000e+03         9.012000e+03   \n",
            "mean         4.346203e+06         1.174126e+04         1.303594e+07   \n",
            "std          2.141192e+08         1.053567e+06         1.179905e+09   \n",
            "min          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "25%          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "50%          0.000000e+00         0.000000e+00         0.000000e+00   \n",
            "75%          2.946467e+01         0.000000e+00         0.000000e+00   \n",
            "max          1.724181e+10         1.000000e+08         1.120000e+11   \n",
            "\n",
            "        ERC20 avg val sent   ERC20 min val sent contract  \\\n",
            "count         9.012000e+03                        9012.0   \n",
            "mean          6.318389e+06                           0.0   \n",
            "std           5.914764e+08                           0.0   \n",
            "min           0.000000e+00                           0.0   \n",
            "25%           0.000000e+00                           0.0   \n",
            "50%           0.000000e+00                           0.0   \n",
            "75%           0.000000e+00                           0.0   \n",
            "max           5.614756e+10                           0.0   \n",
            "\n",
            "        ERC20 max val sent contract   ERC20 avg val sent contract  \\\n",
            "count                        9012.0                        9012.0   \n",
            "mean                            0.0                           0.0   \n",
            "std                             0.0                           0.0   \n",
            "min                             0.0                           0.0   \n",
            "25%                             0.0                           0.0   \n",
            "50%                             0.0                           0.0   \n",
            "75%                             0.0                           0.0   \n",
            "max                             0.0                           0.0   \n",
            "\n",
            "        ERC20 uniq sent token name   ERC20 uniq rec token name  \n",
            "count                  9012.000000                 9012.000000  \n",
            "mean                      1.384931                    4.826676  \n",
            "std                       6.735121                   16.678607  \n",
            "min                       0.000000                    0.000000  \n",
            "25%                       0.000000                    0.000000  \n",
            "50%                       0.000000                    1.000000  \n",
            "75%                       0.000000                    2.000000  \n",
            "max                     213.000000                  737.000000  \n",
            "\n",
            "[8 rows x 48 columns]\n",
            "\n",
            "Missing Values:\n",
            "                                     Missing Count  Percentage\n",
            "Total ERC20 tnxs                               829    8.423941\n",
            "ERC20 total Ether received                     829    8.423941\n",
            "ERC20 total ether sent                         829    8.423941\n",
            "ERC20 total Ether sent contract                829    8.423941\n",
            "ERC20 uniq sent addr                           829    8.423941\n",
            "ERC20 uniq rec addr                            829    8.423941\n",
            "ERC20 uniq sent addr.1                         829    8.423941\n",
            "ERC20 uniq rec contract addr                   829    8.423941\n",
            "ERC20 avg time between sent tnx                829    8.423941\n",
            "ERC20 avg time between rec tnx                 829    8.423941\n",
            "ERC20 avg time between rec 2 tnx               829    8.423941\n",
            "ERC20 avg time between contract tnx            829    8.423941\n",
            "ERC20 min val rec                              829    8.423941\n",
            "ERC20 max val rec                              829    8.423941\n",
            "ERC20 avg val rec                              829    8.423941\n",
            "ERC20 min val sent                             829    8.423941\n",
            "ERC20 max val sent                             829    8.423941\n",
            "ERC20 avg val sent                             829    8.423941\n",
            "ERC20 min val sent contract                    829    8.423941\n",
            "ERC20 max val sent contract                    829    8.423941\n",
            "ERC20 avg val sent contract                    829    8.423941\n",
            "ERC20 uniq sent token name                     829    8.423941\n",
            "ERC20 uniq rec token name                      829    8.423941\n",
            "ERC20 most sent token type                    2697   27.405751\n",
            "ERC20_most_rec_token_type                      871    8.850727\n",
            "\n",
            "Class Distribution (FLAG):\n",
            "FLAG\n",
            "0    7662\n",
            "1    2179\n",
            "Name: count, dtype: int64\n",
            "Fraud Percentage: 22.14%\n",
            "Clean Percentage: 77.86%\n",
            "Imbalance Ratio: 3.52:1\n"
          ]
        }
      ],
      "source": [
        "# EDA\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "\n",
        "# Display basic info\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nFirst Few Rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing,\n",
        "    'Percentage': missing_pct\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "if missing.sum() == 0:\n",
        "    print(\"No missing values found!\")\n",
        "\n",
        "# Check class distribution\n",
        "fraud_col = None\n",
        "for col in ['FLAG', 'Class', 'isFraud', 'Fraud', 'is_fraud']:\n",
        "    if col in df.columns:\n",
        "        fraud_col = col\n",
        "        break\n",
        "\n",
        "if fraud_col:\n",
        "    print(f\"\\nClass Distribution ({fraud_col}):\")\n",
        "    class_dist = df[fraud_col].value_counts()\n",
        "    print(class_dist)\n",
        "    fraud_pct = (class_dist.get(1, 0) / len(df)) * 100\n",
        "    clean_pct = (class_dist.get(0, 0) / len(df)) * 100\n",
        "    print(f\"Fraud Percentage: {fraud_pct:.2f}%\")\n",
        "    print(f\"Clean Percentage: {clean_pct:.2f}%\")\n",
        "\n",
        "    imbalance_ratio = class_dist.get(0, 0) / max(class_dist.get(1, 1), 1)\n",
        "    print(f\"Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "    y = df[fraud_col]\n",
        "else:\n",
        "    print(\"Warning: Could not find fraud label column!\")\n",
        "    print(\"Available columns:\", df.columns.tolist())\n",
        "    y = pd.Series([0] * len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUZ-C7hO-Sku",
        "outputId": "89d2aeee-121a-4c41-e326-ce1c3675a1fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA PREPROCESSING\n",
            "Numeric Features (47): ['Unnamed: 0', 'Index', 'Avg min between sent tnx', 'Avg min between received tnx', 'Time Diff between first and last (Mins)']...\n",
            "Categorical Features (3): ['Address', ' ERC20 most sent token type', ' ERC20_most_rec_token_type']\n",
            "Encoding categorical features...\n",
            "Categorical encoding complete!\n",
            "Handling missing values...\n",
            "Missing values filled with median!\n",
            "Final feature matrix shape: (9841, 50)\n"
          ]
        }
      ],
      "source": [
        "# DATA PREPROCESSING\n",
        "print(\"DATA PREPROCESSING\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[fraud_col] if fraud_col else [], errors='ignore')\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(f\"Numeric Features ({len(numeric_cols)}): {numeric_cols[:5]}{'...' if len(numeric_cols) > 5 else ''}\")\n",
        "print(f\"Categorical Features ({len(categorical_cols)}): {categorical_cols}\")\n",
        "\n",
        "# Handle categorical features\n",
        "if categorical_cols:\n",
        "    print(\"Encoding categorical features...\")\n",
        "    le = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        X[col] = le.fit_transform(X[col].astype(str))\n",
        "    print(\"Categorical encoding complete!\")\n",
        "\n",
        "# Handle missing values\n",
        "if X.isnull().sum().sum() > 0:\n",
        "    print(\"Handling missing values...\")\n",
        "    X = X.fillna(X.median())\n",
        "    print(\"Missing values filled with median!\")\n",
        "\n",
        "# Remove any non-numeric columns\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "print(f\"Final feature matrix shape: {X.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssF-cOCX-aJs",
        "outputId": "c7168a09-bbbb-4861-b39a-f4cf9aba37df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "GENERATING VISUALIZATIONS\n",
            "================================================================================\n",
            "✓ Saved: feature_distributions.png\n",
            "Generating correlation heatmap...\n",
            "✓ Saved: correlation_heatmap.png\n",
            "✓ Saved: class_distribution.png\n"
          ]
        }
      ],
      "source": [
        "# VISUALISATION - FEATURE DISTRIBUTIONS\n",
        "print(\"GENERATING VISUALIZATIONS\")\n",
        "\n",
        "# Plot distributions of key features\n",
        "n_features_to_plot = min(6, len(X.columns))\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Feature Distributions', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, col in enumerate(X.columns[:n_features_to_plot]):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "    ax.hist(X[col], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    ax.set_title(f'{col}', fontweight='bold')\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: feature_distributions.png\")\n",
        "plt.close()\n",
        "\n",
        "# Correlation heatmap\n",
        "print(\"Generating correlation heatmap...\")\n",
        "plt.figure(figsize=(14, 12))\n",
        "correlation_matrix = X.corr()\n",
        "\n",
        "# For large datasets, show only top correlations\n",
        "if len(X.columns) > 20:\n",
        "    top_features = X.var().nlargest(20).index\n",
        "    correlation_matrix = X[top_features].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=0.5, cbar_kws={'label': 'Correlation'})\n",
        "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: correlation_heatmap.png\")\n",
        "plt.close()\n",
        "\n",
        "# Class distribution visualization\n",
        "if fraud_col:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Bar plot\n",
        "    class_counts = y.value_counts()\n",
        "    axes[0].bar(['Clean', 'Fraud'], class_counts.values, color=['green', 'red'], alpha=0.7)\n",
        "    axes[0].set_ylabel('Count', fontweight='bold')\n",
        "    axes[0].set_title('Class Distribution', fontweight='bold')\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Pie chart\n",
        "    axes[1].pie(class_counts.values, labels=['Clean', 'Fraud'], autopct='%1.2f%%',\n",
        "                colors=['green', 'red'], startangle=90)\n",
        "    axes[1].set_title('Class Proportion', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"✓ Saved: class_distribution.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk4I16OG-fK3",
        "outputId": "3b55bc23-4bcb-4124-a8ca-be8dea124b2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAIN/TEST SPLIT\n",
            "================================================================================\n",
            "Training set: 6,888 samples\n",
            "   Clean: 5,363 | Fraud: 1,525\n",
            "Test set: 2,953 samples\n",
            "   Clean: 2,299 | Fraud: 654\n",
            "\n",
            "Normalizing features with StandardScaler...\n",
            "Feature scaling complete!\n"
          ]
        }
      ],
      "source": [
        "# TRAIN/TEST SPLIT\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TRAIN/TEST SPLIT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y if fraud_col else None\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
        "print(f\"   Clean: {(y_train == 0).sum():,} | Fraud: {(y_train == 1).sum():,}\")\n",
        "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
        "print(f\"   Clean: {(y_test == 0).sum():,} | Fraud: {(y_test == 1).sum():,}\")\n",
        "\n",
        "# Normalize features\n",
        "print(\"\\nNormalizing features with StandardScaler...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Feature scaling complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIwGnaD6-i_N",
        "outputId": "7a0e3505-470a-41b1-be47-148b2843f0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HANDLING CLASS IMBALANCE\n",
            "Class imbalance is manageable (ratio: 3.52:1)\n",
            "Using scale_pos_weight parameter in XGBoost\n"
          ]
        }
      ],
      "source": [
        "# HANDLE CLASS IMBALANCE\n",
        "print(\"HANDLING CLASS IMBALANCE\")\n",
        "\n",
        "if fraud_col and y_train.sum() > 0:\n",
        "    imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "    if imbalance_ratio > 5:\n",
        "        print(f\"Severe class imbalance detected (ratio: {imbalance_ratio:.2f}:1)\")\n",
        "        print(\"Applying SMOTE + Random Under-sampling...\")\n",
        "\n",
        "        # Calculate sampling strategy\n",
        "        n_fraud = (y_train == 1).sum()\n",
        "        n_clean = (y_train == 0).sum()\n",
        "\n",
        "        # SMOTE to oversample minority class\n",
        "        over_sample_ratio = min(0.5, n_fraud / n_clean * 3)\n",
        "        # Under-sample majority class\n",
        "        under_sample_ratio = min(0.8, n_fraud * 2 / n_clean)\n",
        "\n",
        "        over = SMOTE(sampling_strategy=over_sample_ratio, random_state=42)\n",
        "        under = RandomUnderSampler(sampling_strategy=under_sample_ratio, random_state=42)\n",
        "\n",
        "        steps = [('over', over), ('under', under)]\n",
        "        pipeline = ImbPipeline(steps=steps)\n",
        "\n",
        "        X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "        print(f\"Resampling complete!\")\n",
        "        print(f\"   Before: Clean={n_clean:,}, Fraud={n_fraud:,}\")\n",
        "        print(f\"   After: Clean={(y_train_resampled == 0).sum():,}, Fraud={(y_train_resampled == 1).sum():,}\")\n",
        "\n",
        "        X_train_final = X_train_resampled\n",
        "        y_train_final = y_train_resampled\n",
        "    else:\n",
        "        print(f\"Class imbalance is manageable (ratio: {imbalance_ratio:.2f}:1)\")\n",
        "        print(\"Using scale_pos_weight parameter in XGBoost\")\n",
        "        X_train_final = X_train_scaled\n",
        "        y_train_final = y_train\n",
        "else:\n",
        "    X_train_final = X_train_scaled\n",
        "    y_train_final = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdXhWZB9-osR",
        "outputId": "486f9718-1ea2-458d-f430-8650bd9d1682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL TRAINING - XGBOOST\n",
            "Scale Pos Weight: 3.52\n",
            "\n",
            "Performing hyperparameter tuning with GridSearchCV...\n",
            "Training XGBoost with cross-validation...\n",
            "This may take a few minutes...\n",
            "Fitting 3 folds for each of 2187 candidates, totalling 6561 fits\n",
            "\n",
            "Training complete!\n",
            "Best parameters found:\n",
            "   colsample_bytree: 0.8\n",
            "   gamma: 0\n",
            "   learning_rate: 0.01\n",
            "   max_depth: 3\n",
            "   min_child_weight: 1\n",
            "   n_estimators: 100\n",
            "   subsample: 0.8\n",
            "Best cross-validation F1-score: 1.0000\n",
            "\n",
            "Training final model with best parameters...\n",
            "Final model training complete!\n"
          ]
        }
      ],
      "source": [
        "# MODEL TRAINING - XGBOOST\n",
        "print(\"MODEL TRAINING - XGBOOST\")\n",
        "\n",
        "# Calculate scale_pos_weight for imbalanced data\n",
        "if fraud_col and y_train_final.sum() > 0:\n",
        "    scale_pos_weight = (y_train_final == 0).sum() / (y_train_final == 1).sum()\n",
        "else:\n",
        "    scale_pos_weight = 1\n",
        "\n",
        "print(f\"Scale Pos Weight: {scale_pos_weight:.2f}\")\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "print(\"\\nPerforming hyperparameter tuning with GridSearchCV...\")\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Initial model\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "# GridSearchCV with cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1',\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Training XGBoost with cross-validation...\")\n",
        "print(\"This may take a few minutes...\")\n",
        "\n",
        "grid_search.fit(X_train_final, y_train_final)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"\\nTraining complete!\")\n",
        "print(f\"Best parameters found:\")\n",
        "for param, value in grid_search.best_params_.items():\n",
        "    print(f\"   {param}: {value}\")\n",
        "print(f\"Best cross-validation F1-score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Train final model with best parameters\n",
        "print(\"\\nTraining final model with best parameters...\")\n",
        "final_model = xgb.XGBClassifier(\n",
        "    **grid_search.best_params_,\n",
        "    objective='binary:logistic',\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "final_model.fit(X_train_final, y_train_final)\n",
        "print(\"Final model training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eO6eCGw2-shQ",
        "outputId": "81cf4b3a-0db2-47e9-af15-ef2614b4d905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREDICTIONS AND SCORING\n",
            "Prediction Statistics:\n",
            "   Predicted Fraud: 654 (22.15%)\n",
            "   Predicted Clean: 2,299 (77.85%)\n",
            "\n",
            "Fraud Probability Statistics:\n",
            "   Min: 0.1830\n",
            "   Max: 0.8141\n",
            "   Mean: 0.3273\n",
            "   Median: 0.1915\n",
            "\n",
            "Fraud Risk Rating (1-10) Statistics:\n",
            "   Min: 2.7\n",
            "   Max: 8.4\n",
            "   Mean: 7.1\n",
            "   Median: 8.3\n"
          ]
        }
      ],
      "source": [
        "# PREDICTIONS AND SCORING\n",
        "print(\"PREDICTIONS AND SCORING\")\n",
        "\n",
        "# Get predictions\n",
        "y_pred = final_model.predict(X_test_scaled)\n",
        "y_pred_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Create fraud risk rating (1-10 scale)\n",
        "# Higher probability of fraud = lower rating (more risky)\n",
        "fraud_risk_rating = (1 - y_pred_proba) * 9 + 1\n",
        "fraud_risk_rating = np.round(fraud_risk_rating, 1)\n",
        "\n",
        "print(f\"Prediction Statistics:\")\n",
        "print(f\"   Predicted Fraud: {y_pred.sum():,} ({y_pred.sum() / len(y_pred) * 100:.2f}%)\")\n",
        "print(f\"   Predicted Clean: {(y_pred == 0).sum():,} ({(y_pred == 0).sum() / len(y_pred) * 100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nFraud Probability Statistics:\")\n",
        "print(f\"   Min: {y_pred_proba.min():.4f}\")\n",
        "print(f\"   Max: {y_pred_proba.max():.4f}\")\n",
        "print(f\"   Mean: {y_pred_proba.mean():.4f}\")\n",
        "print(f\"   Median: {np.median(y_pred_proba):.4f}\")\n",
        "\n",
        "print(f\"\\nFraud Risk Rating (1-10) Statistics:\")\n",
        "print(f\"   Min: {fraud_risk_rating.min():.1f}\")\n",
        "print(f\"   Max: {fraud_risk_rating.max():.1f}\")\n",
        "print(f\"   Mean: {fraud_risk_rating.mean():.1f}\")\n",
        "print(f\"   Median: {np.median(fraud_risk_rating):.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lhqMGXQx--5A",
        "outputId": "7282fec9-c3d4-4ef9-9929-a1b41608d388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL EVALUATION\n",
            "Performance Metrics:\n",
            "   Accuracy:  1.0000\n",
            "   Precision: 1.0000\n",
            "   Recall:    1.0000\n",
            "   F1-Score:  1.0000\n",
            "   ROC-AUC:   1.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "              Clean  Fraud\n",
            "Actual Clean   2299      0\n",
            "       Fraud      0    654\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Clean       1.00      1.00      1.00      2299\n",
            "       Fraud       1.00      1.00      1.00       654\n",
            "\n",
            "    accuracy                           1.00      2953\n",
            "   macro avg       1.00      1.00      1.00      2953\n",
            "weighted avg       1.00      1.00      1.00      2953\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MODEL EVALUATION\n",
        "print(\"MODEL EVALUATION\")\n",
        "\n",
        "if y_test.sum() > 0:\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    print(f\"Performance Metrics:\")\n",
        "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"   Precision: {precision:.4f}\")\n",
        "    print(f\"   Recall:    {recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {f1:.4f}\")\n",
        "    print(f\"   ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"                 Predicted\")\n",
        "    print(f\"              Clean  Fraud\")\n",
        "    print(f\"Actual Clean  {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
        "    print(f\"       Fraud  {cm[1,0]:5d}  {cm[1,1]:5d}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred,\n",
        "                                target_names=['Clean', 'Fraud'],\n",
        "                                zero_division=0))\n",
        "else:\n",
        "    print(\"No fraud samples in test set - skipping evaluation\")\n",
        "    roc_auc = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hD1ksBKE_Dz5",
        "outputId": "0faf1de5-a8ff-44fa-b3e1-328db23171b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FEATURE IMPORTANCE ANALYSIS\n",
            "Top 10 Most Important Features:\n",
            "                                Feature  Importance\n",
            "                             Unnamed: 0    0.452673\n",
            "                       Total ERC20 tnxs    0.141565\n",
            "              ERC20_most_rec_token_type    0.130724\n",
            "Time Diff between first and last (Mins)    0.095096\n",
            "                      ERC20 max val rec    0.056555\n",
            "             ERC20 most sent token type    0.041905\n",
            "                    total ether balance    0.020444\n",
            "           Avg min between received tnx    0.016405\n",
            "                           min val sent    0.014043\n",
            "                     ERC20 avg val sent    0.010523\n",
            "\n",
            "Saved: feature_importance.png\n",
            "GENERATING RESULT VISUALIZATIONS\n",
            "Saved: confusion_matrix.png\n",
            "✓ Saved: fraud_probability_distribution.png\n",
            "✓ Saved: roc_curve.png\n",
            "✓ Saved: precision_recall_curve.png\n"
          ]
        }
      ],
      "source": [
        "# FEATURE IMPORTANCE\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"Top 10 Most Important Features:\")\n",
        "print(feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = feature_importance.head(20)\n",
        "plt.barh(range(len(top_features)), top_features['Importance'], color='steelblue')\n",
        "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "plt.xlabel('Importance Score', fontweight='bold', fontsize=12)\n",
        "plt.ylabel('Features', fontweight='bold', fontsize=12)\n",
        "plt.title('Top 20 Feature Importances - XGBoost', fontweight='bold', fontsize=14)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\nSaved: feature_importance.png\")\n",
        "plt.close()\n",
        "\n",
        "# VISUALIZATIONS - RESULTS\n",
        "print(\"GENERATING RESULT VISUALIZATIONS\")\n",
        "\n",
        "# Confusion Matrix Heatmap\n",
        "if y_test.sum() > 0:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "                xticklabels=['Clean', 'Fraud'],\n",
        "                yticklabels=['Clean', 'Fraud'])\n",
        "    plt.title('Confusion Matrix', fontweight='bold', fontsize=14)\n",
        "    plt.ylabel('Actual Label', fontweight='bold', fontsize=12)\n",
        "    plt.xlabel('Predicted Label', fontweight='bold', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Fraud Probability Distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "axes[0].hist(y_pred_proba[y_test == 0], bins=50, alpha=0.7, label='Clean', color='green')\n",
        "axes[0].hist(y_pred_proba[y_test == 1], bins=50, alpha=0.7, label='Fraud', color='red')\n",
        "axes[0].set_xlabel('Fraud Probability', fontweight='bold')\n",
        "axes[0].set_ylabel('Frequency', fontweight='bold')\n",
        "axes[0].set_title('Fraud Probability Distribution', fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].hist(fraud_risk_rating[y_test == 0], bins=50, alpha=0.7, label='Clean', color='green')\n",
        "axes[1].hist(fraud_risk_rating[y_test == 1], bins=50, alpha=0.7, label='Fraud', color='red')\n",
        "axes[1].set_xlabel('Fraud Risk Rating (1-10)', fontweight='bold')\n",
        "axes[1].set_ylabel('Frequency', fontweight='bold')\n",
        "axes[1].set_title('Fraud Risk Rating Distribution', fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fraud_probability_distribution.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✓ Saved: fraud_probability_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "# ROC Curve\n",
        "if roc_auc is not None:\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'XGBoost (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
        "             label='Random Classifier (AUC = 0.50)')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontweight='bold', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontweight='bold', fontsize=12)\n",
        "    plt.title('ROC Curve - XGBoost Fraud Detection', fontweight='bold', fontsize=14)\n",
        "    plt.legend(loc=\"lower right\", fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "if y_test.sum() > 0:\n",
        "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "    pr_auc = auc(recall_vals, precision_vals)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(recall_vals, precision_vals, color='darkorange', lw=2,\n",
        "             label=f'XGBoost (AUC = {pr_auc:.4f})')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Recall', fontweight='bold', fontsize=12)\n",
        "    plt.ylabel('Precision', fontweight='bold', fontsize=12)\n",
        "    plt.title('Precision-Recall Curve - XGBoost', fontweight='bold', fontsize=14)\n",
        "    plt.legend(loc=\"lower left\", fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: precision_recall_curve.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-AK_QDgM_Ix0",
        "outputId": "0ba2dc98-9f46-4ea2-9f12-90b642bb8f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FINAL RESULTS OUTPUT\n",
            "\n",
            "Sample Results (Top 10 Highest Risk):\n",
            " Transaction_Index  Fraud_Probability Prediction  Fraud_Risk_Rating_1_10 Actual_Label  Correct_Prediction\n",
            "              9665            0.81414      Fraud                     2.7        Fraud                True\n",
            "              9614            0.81414      Fraud                     2.7        Fraud                True\n",
            "              9305            0.81414      Fraud                     2.7        Fraud                True\n",
            "              9015            0.81414      Fraud                     2.7        Fraud                True\n",
            "              8389            0.81414      Fraud                     2.7        Fraud                True\n",
            "              9704            0.81414      Fraud                     2.7        Fraud                True\n",
            "              8679            0.81414      Fraud                     2.7        Fraud                True\n",
            "              9742            0.81414      Fraud                     2.7        Fraud                True\n",
            "              7801            0.81414      Fraud                     2.7        Fraud                True\n",
            "              7937            0.81414      Fraud                     2.7        Fraud                True\n",
            "\n",
            "Sample Results (Top 10 Lowest Risk):\n",
            " Transaction_Index  Fraud_Probability Prediction  Fraud_Risk_Rating_1_10 Actual_Label  Correct_Prediction\n",
            "              2352           0.182971      Clean                     8.4        Clean                True\n",
            "               853           0.182971      Clean                     8.4        Clean                True\n",
            "              1274           0.182971      Clean                     8.4        Clean                True\n",
            "              5954           0.182971      Clean                     8.4        Clean                True\n",
            "              6320           0.182971      Clean                     8.4        Clean                True\n",
            "              3569           0.182971      Clean                     8.4        Clean                True\n",
            "              7569           0.182971      Clean                     8.4        Clean                True\n",
            "              1742           0.182971      Clean                     8.4        Clean                True\n",
            "              6335           0.182971      Clean                     8.4        Clean                True\n",
            "              5047           0.182971      Clean                     8.4        Clean                True\n",
            "\n",
            "Full results saved to: fraud_detection_results_xgboost.csv\n",
            "Feature importance saved to: feature_importance_xgboost.csv\n",
            "SUMMARY\n",
            "Total transactions analyzed: 2,953\n",
            "Flagged as fraud: 654 (22.15%)\n",
            "Flagged as clean: 2,299 (77.85%)\n",
            "\n",
            "Model Performance Summary:\n",
            "   • Accuracy:  100.00% (overall correctness)\n",
            "   • Precision: 100.00% (of flagged frauds, how many were correct)\n",
            "   • Recall:    100.00% (of actual frauds, how many were caught)\n",
            "   • F1-Score:  1.0000 (harmonic mean of precision and recall)\n",
            "   • ROC-AUC:   1.0000 (overall discriminative ability)\n",
            "   • Specificity: 100.00% (true negative rate)\n",
            "   • Fraud Detection Rate: 100.00%\n",
            "FRAUD DETECTION ANALYSIS COMPLETE!\n",
            "================================================================================\n",
            "Generated Files:\n",
            "   • feature_distributions.png\n",
            "   • correlation_heatmap.png\n",
            "   • class_distribution.png\n",
            "   • feature_importance.png\n",
            "   • confusion_matrix.png\n",
            "   • fraud_probability_distribution.png\n",
            "   • roc_curve.png\n",
            "   • precision_recall_curve.png\n",
            "   • fraud_detection_results_xgboost.csv\n",
            "   • feature_importance_xgboost.csv\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# OUTPUT RESULTS\n",
        "print(\"FINAL RESULTS OUTPUT\")\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Transaction_Index': X_test.index,\n",
        "    'Fraud_Probability': y_pred_proba,\n",
        "    'Prediction': ['Fraud' if p == 1 else 'Clean' for p in y_pred],\n",
        "    'Fraud_Risk_Rating_1_10': fraud_risk_rating,\n",
        "    'Actual_Label': ['Fraud' if y == 1 else 'Clean' for y in y_test],\n",
        "    'Correct_Prediction': y_pred == y_test\n",
        "})\n",
        "\n",
        "# Sort by fraud risk (highest probability = highest risk)\n",
        "results_df = results_df.sort_values('Fraud_Probability', ascending=False)\n",
        "\n",
        "print(\"\\nSample Results (Top 10 Highest Risk):\")\n",
        "print(results_df.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nSample Results (Top 10 Lowest Risk):\")\n",
        "print(results_df.tail(10).to_string(index=False))\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('fraud_detection_results_xgboost.csv', index=False)\n",
        "print(\"\\nFull results saved to: fraud_detection_results_xgboost.csv\")\n",
        "\n",
        "# Save feature importance\n",
        "feature_importance.to_csv('feature_importance_xgboost.csv', index=False)\n",
        "print(\"Feature importance saved to: feature_importance_xgboost.csv\")\n",
        "\n",
        "# SUMMARY\n",
        "print(\"SUMMARY\")\n",
        "print(f\"Total transactions analyzed: {len(results_df):,}\")\n",
        "print(f\"Flagged as fraud: {(y_pred == 1).sum():,} ({(y_pred == 1).sum() / len(y_pred) * 100:.2f}%)\")\n",
        "print(f\"Flagged as clean: {(y_pred == 0).sum():,} ({(y_pred == 0).sum() / len(y_pred) * 100:.2f}%)\")\n",
        "\n",
        "if y_test.sum() > 0:\n",
        "    print(f\"\\nModel Performance Summary:\")\n",
        "    print(f\"   • Accuracy:  {accuracy:.2%} (overall correctness)\")\n",
        "    print(f\"   • Precision: {precision:.2%} (of flagged frauds, how many were correct)\")\n",
        "    print(f\"   • Recall:    {recall:.2%} (of actual frauds, how many were caught)\")\n",
        "    print(f\"   • F1-Score:  {f1:.4f} (harmonic mean of precision and recall)\")\n",
        "    print(f\"   • ROC-AUC:   {roc_auc:.4f} (overall discriminative ability)\")\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    print(f\"   • Specificity: {specificity:.2%} (true negative rate)\")\n",
        "\n",
        "    if tp + fn > 0:\n",
        "        fraud_detection_rate = tp / (tp + fn)\n",
        "        print(f\"   • Fraud Detection Rate: {fraud_detection_rate:.2%}\")\n",
        "\n",
        "\n",
        "print(\"FRAUD DETECTION ANALYSIS COMPLETE!\")\n",
        "print(\"Generated Files:\")\n",
        "print(\"   • feature_distributions.png\")\n",
        "print(\"   • correlation_heatmap.png\")\n",
        "print(\"   • class_distribution.png\")\n",
        "print(\"   • feature_importance.png\")\n",
        "print(\"   • confusion_matrix.png\")\n",
        "print(\"   • fraud_probability_distribution.png\")\n",
        "print(\"   • roc_curve.png\")\n",
        "print(\"   • precision_recall_curve.png\")\n",
        "print(\"   • fraud_detection_results_xgboost.csv\")\n",
        "print(\"   • feature_importance_xgboost.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LQZdJ-nEBzl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}